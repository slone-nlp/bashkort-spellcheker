{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f75b144",
   "metadata": {},
   "source": [
    "The same idea as in the Notebook 6, but with a more efficient model architecture: https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/reformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f6e47",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fc96a",
   "metadata": {},
   "source": [
    "## 1. 1. Load the parallel text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaffe14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trash</th>\n",
       "      <th>clean</th>\n",
       "      <th>trash2</th>\n",
       "      <th>clean2</th>\n",
       "      <th>distance</th>\n",
       "      <th>normalized_distance</th>\n",
       "      <th>split</th>\n",
       "      <th>edit_max_cldiff</th>\n",
       "      <th>edit_max_lendiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–®—É–Ω–¥–∞ —É–∫ ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...</td>\n",
       "      <td>–®—É–Ω–¥–∞ —É“° ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...</td>\n",
       "      <td>–®—É–Ω–¥–∞ —É–∫ ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...</td>\n",
       "      <td>–®—É–Ω–¥–∞ —É“° ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–£–Ω–∞–Ω –±–µ“ô ”©—Å”©–±”©“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.</td>\n",
       "      <td>–£–Ω–∞–Ω –±–µ“ô ”ô—Å”ô–±–µ“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.</td>\n",
       "      <td>–£–Ω–∞–Ω –±–µ“ô ”©—Å”©–±”©“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.</td>\n",
       "      <td>–£–Ω–∞–Ω –±–µ“ô ”ô—Å”ô–±–µ“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬´–ò“´”ô–Ω-“∫–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...</td>\n",
       "      <td>¬´–ò“´”ô–Ω-“ª–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...</td>\n",
       "      <td>¬´–ò“´”ô–Ω-“∫–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...</td>\n",
       "      <td>¬´–ò“´”ô–Ω-“ª–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω–∞—É...</td>\n",
       "      <td>–ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, - —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω...</td>\n",
       "      <td>–ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω–∞—É...</td>\n",
       "      <td>–ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, - —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...</td>\n",
       "      <td>–ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...</td>\n",
       "      <td>–ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...</td>\n",
       "      <td>–ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23886</th>\n",
       "      <td>–≠“´—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...</td>\n",
       "      <td>–≠—Å—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...</td>\n",
       "      <td>–≠“´—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...</td>\n",
       "      <td>–≠—Å—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23887</th>\n",
       "      <td>“Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© –ö”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...</td>\n",
       "      <td>“Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© “†”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...</td>\n",
       "      <td>“Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© –ö”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...</td>\n",
       "      <td>“Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© “†”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>–ö–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...</td>\n",
       "      <td>“†–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...</td>\n",
       "      <td>–ö–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...</td>\n",
       "      <td>“†–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>–ö—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...</td>\n",
       "      <td>“†—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...</td>\n",
       "      <td>–ö—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...</td>\n",
       "      <td>“†—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23890</th>\n",
       "      <td>–®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä “°—É–ø—à—ã “ì—ã–Ω–∞ –∏—Ç–µ...</td>\n",
       "      <td>–®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä - “°—É–ø—à—ã “ì—ã–Ω–∞ –∏...</td>\n",
       "      <td>–®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä “°—É–ø—à—ã “ì—ã–Ω–∞ –∏—Ç–µ...</td>\n",
       "      <td>–®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä - “°—É–ø—à—ã “ì—ã–Ω–∞ –∏...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23891 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   trash  \\\n",
       "0      –®—É–Ω–¥–∞ —É–∫ ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...   \n",
       "1            –£–Ω–∞–Ω –±–µ“ô ”©—Å”©–±”©“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.   \n",
       "2      ¬´–ò“´”ô–Ω-“∫–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...   \n",
       "3      –ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω–∞—É...   \n",
       "4      –ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...   \n",
       "...                                                  ...   \n",
       "23886  –≠“´—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...   \n",
       "23887  “Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© –ö”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...   \n",
       "23888  –ö–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...   \n",
       "23889  –ö—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...   \n",
       "23890  –®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä “°—É–ø—à—ã “ì—ã–Ω–∞ –∏—Ç–µ...   \n",
       "\n",
       "                                                   clean  \\\n",
       "0      –®—É–Ω–¥–∞ —É“° ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...   \n",
       "1            –£–Ω–∞–Ω –±–µ“ô ”ô—Å”ô–±–µ“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.   \n",
       "2      ¬´–ò“´”ô–Ω-“ª–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...   \n",
       "3      –ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, - —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω...   \n",
       "4      –ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...   \n",
       "...                                                  ...   \n",
       "23886  –≠—Å—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...   \n",
       "23887  “Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© “†”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...   \n",
       "23888  “†–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...   \n",
       "23889  “†—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...   \n",
       "23890  –®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä - “°—É–ø—à—ã “ì—ã–Ω–∞ –∏...   \n",
       "\n",
       "                                                  trash2  \\\n",
       "0      –®—É–Ω–¥–∞ —É–∫ ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...   \n",
       "1            –£–Ω–∞–Ω –±–µ“ô ”©—Å”©–±”©“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.   \n",
       "2      ¬´–ò“´”ô–Ω-“∫–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...   \n",
       "3      –ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω–∞—É...   \n",
       "4      –ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...   \n",
       "...                                                  ...   \n",
       "23886  –≠“´—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...   \n",
       "23887  “Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© –ö”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...   \n",
       "23888  –ö–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...   \n",
       "23889  –ö—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...   \n",
       "23890  –®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä “°—É–ø—à—ã “ì—ã–Ω–∞ –∏—Ç–µ...   \n",
       "\n",
       "                                                  clean2  distance  \\\n",
       "0      –®—É–Ω–¥–∞ —É“° ”ô—Å”ô–π–µ–º–¥–µ“£ —Ç–æ“°—Å–∞–π—ã–Ω, —Ç”©–π”©–Ω—Å”©–∫—Ç”ô—Ä–µ–Ω –∫“Ø“ô...         1   \n",
       "1            –£–Ω–∞–Ω –±–µ“ô ”ô—Å”ô–±–µ“ô “ô”ô —É–ª—Ç—ã—Ä“ì—ã—Å—Ç–∞—Ä“ì–∞ —É–ª—Ç—ã—Ä–∞–±—ã“ô.         3   \n",
       "2      ¬´–ò“´”ô–Ω-“ª–∞—É “ì—ã–Ω–∞ —Ç–æ—Ä–æ“ì–æ“ô –∏–Ω–¥–µ¬ª, - —Ç–∏–ø –±—ã—à—ã–ª–¥–∞–π —É...         1   \n",
       "3      –ú–∏–Ω–µ“£ –≥–µ–Ω”ô –±–µ—Ä –∫–µ—à–µ–º –¥”ô —é“°, - —Ç–∏–ø —à—É–Ω–¥–∞ —É“° —Ç–∞–Ω...         2   \n",
       "4      –ê–π –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –π—ã–ª –π”©—Ä”©–≥”ô–Ω, —Ç–∏, –±–∞—Ç—ã—Ä, –µ—Ç–µ —Ç–∞...         1   \n",
       "...                                                  ...       ...   \n",
       "23886  –≠—Å—Ç”ô—Ä–µ–Ω–¥”ô –±“Ø—Ä–µ “Ø–∫ –æ–ª–æ–º–∞“ª–∞ –ª–∞, —ç—Ç—Ç”ô—Ä —à—ã“£—à—ã–π –±–∞—à...         1   \n",
       "23887  “Æ—Ç–∫”ô–Ω –π”ô–π“ô”ô —è–º–∞–Ω —Ç–æ–º—Ä–∞ –∫”©–Ω–¥”© “†”ô“ô–µ—Ä“ì–æ–ª —Ç”©–±”ô–≥–µ–Ω–¥...         1   \n",
       "23888  “†–∞–π—Ç—ã—Ä –∞–ª–¥—ã–Ω–∞–Ω —Å–∞–ª–±–∞—Ä“ô—ã —ç“ô–ª”ô–π –±–∞—à–ª–∞“ª–∞, —Ç–∞–±–∞ –∞–ª...         1   \n",
       "23889  “†—ã—à —É—Ä—Ç–∞–ª–∞—Ä—ã–Ω–¥–∞ –±–µ—Ä –∫”©–Ω ”ò–±–¥—Ä”ô—à–∏—Ç –∞—Ç –∞“ô–±–∞—Ä—ã–Ω–∞–Ω ...         1   \n",
       "23890  –®–∞—Ç–ª—ã“° —Ç–∏–≥”ô–Ω–µ–±–µ“ô —é“ì–∞–ª“ì–∞–Ω —Å–∞–ª–±–∞—Ä - “°—É–ø—à—ã “ì—ã–Ω–∞ –∏...         2   \n",
       "\n",
       "       normalized_distance  split  edit_max_cldiff  edit_max_lendiff  \n",
       "0                 0.015385  train                1                 0  \n",
       "1                 0.069767   test                1                 0  \n",
       "2                 0.014085    dev                1                 0  \n",
       "3                 0.029412  train                0                 0  \n",
       "4                 0.012500  train                1                 0  \n",
       "...                    ...    ...              ...               ...  \n",
       "23886             0.020000    dev                1                 0  \n",
       "23887             0.009524  train                1                 0  \n",
       "23888             0.020000  train                1                 0  \n",
       "23889             0.009174  train                1                 0  \n",
       "23890             0.021053  train                0                 0  \n",
       "\n",
       "[23891 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv('../data/spellchecker_dataset_split.tsv', sep='\\t')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b03813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14382, 9)\n",
      "(14171, 9)\n",
      "(14085, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_train = df_orig[(df_orig.split=='train')]\n",
    "print(df_orig_train.shape)\n",
    "\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_cldiff <= 3]\n",
    "print(df_orig_train.shape)\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_lendiff <= 1].copy()\n",
    "print(df_orig_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5f5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4611, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_dev = df_orig[(df_orig.split=='dev') & (df_orig.edit_max_cldiff <= 3) & (df_orig.edit_max_lendiff <= 1)]\n",
    "print(df_orig_dev.shape)\n",
    "dev_small = df_orig_dev.sample(100, random_state=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154994",
   "metadata": {},
   "source": [
    "## 1.2. Corrupt the clean sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851b9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605495\n"
     ]
    }
   ],
   "source": [
    "with open('../data/clean_bk_sents.txt', 'r') as f:\n",
    "    cs2 = [line.strip() for line in f]\n",
    "print(len(cs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ba88fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~¬Å¬†¬¢¬¶¬ß¬™¬´¬¨¬≠¬Æ¬∞¬≤¬µ¬∑¬ª¬ø√Ä√Å√Ç√Ñ√â√ä√å√ç√é√ê√í√ñ√ó√ò√ú√ù√û√†√°√¢√£√§√•√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∑√∏√ª√º√Ω√øƒÅƒåƒçƒüƒ±≈Ç≈†≈°≈´≈Ω≈æ∆è…ô…µ ∫ÃÅÃ∂ŒíŒ†Œß–Å–É–Ñ–Ö–Ü–â–ã–è–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—í—ì—î—ï—ñ—ó—ô—ö—õ—ú—û—ü—≤—≥“ê“í“ì“ñ“ó“ò“ô“õ“†“°“¢“£“™“´“Æ“Ø“∞“∫“ª”ä”ò”ô”ß”®”©ÿßÿ™ÿÆÿ±ÿ≥ÿπŸÉŸÜŸà‚Äà‚Äâ‚Äã‚Äé‚Äê‚Äë‚Äí‚Äì‚Äî‚Äï‚Äò‚Äô‚Äú‚Äù‚Äû‚Ä¢‚Ä¶‚ÄØ‚Ä∞‚Ä∫‚Å†‚Ññ‚Ö†‚Üí‚àÇ‚àí‚â•‚è∞‚îÄ‚óè‚òé‚ö°‚úí‚úì‚ú®ÔÄ≠ÔÇÖÔÇáÔÇéÔÇíÔÇñÔÇùÔÇûÔÇüÔÇ°ÔÇ´ÔÇ≠ÔÇ¥ÔÇ∏ÔÇπÔÇªÔÉµÔªøüå∏üé≠üìù\n",
      "354\n",
      "\t !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~¬Å¬†¬¢¬¶¬ß¬™¬´¬¨¬≠¬Æ¬∞¬≤¬µ¬∑¬ª¬ø√Ä√Å√Ç√É√Ñ√Ö√á√à√â√ä√ã√å√ç√é√è√ê√ë√í√ì√î√ï√ñ√ó√ò√õ√ú√ù√û√†√°√¢√£√§√•√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∑√∏√ª√º√Ω√æ√øƒÄƒÅƒåƒçƒûƒüƒ±≈Å≈Ç≈†≈°≈™≈´≈∏≈Ω≈æ∆è∆ü…ô…µ ∫ÃÅÃ∂ŒíŒúŒ†ŒßŒ≤œÄœá–Å–Ç–É–Ñ–Ö–Ü–á–â–ä–ã–å–é–è–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë—í—ì—î—ï—ñ—ó—ô—ö—õ—ú—û—ü—≤—≥“ê“ë“í“ì“ñ“ó“ò“ô“ö“õ“†“°“¢“£“™“´“Æ“Ø“∞“±“∫“ª”â”ä”ò”ô”¶”ß”®”©ÿßÿ™ÿÆÿ±ÿ≥ÿπŸÉŸÜŸà‚Äà‚Äâ‚Äã‚Äé‚Äê‚Äë‚Äí‚Äì‚Äî‚Äï‚Äò‚Äô‚Äú‚Äù‚Äû‚Ä¢‚Ä¶‚ÄØ‚Ä∞‚Ä∫‚Å†‚Ññ‚Ö†‚Ö∞‚Üí‚àÇ‚àí‚â•‚è∞‚îÄ‚óè‚òé‚ö°‚úí‚úì‚ú®ÔÄ≠ÔÇÖÔÇáÔÇéÔÇíÔÇñÔÇùÔÇûÔÇüÔÇ°ÔÇ´ÔÇ≠ÔÇ¥ÔÇ∏ÔÇπÔÇªÔÉµÔªøüå∏üé≠üìù\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "all_chars = ''.join(sorted({\n",
    "    c for texts in [cs2, df_orig_train.trash, df_orig_train.clean] \n",
    "    for text in texts for c in text\n",
    "}))\n",
    "print(all_chars)\n",
    "print(len(all_chars))\n",
    "\n",
    "all_chars = ''.join(sorted(set(all_chars + all_chars.upper() + all_chars.lower())))\n",
    "print(all_chars)\n",
    "print(len(all_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3120603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisers import add_simple_noise\n",
    "from noisers import Noiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e058f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = Noiser.load('noise_model_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd24e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä\\xad–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = random.choice(cs2)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797922d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å√Ç–µ, ”ô—Ä\\xad–±–∏”ô –±…µ—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µJ–º–µ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_simple_noise(text, all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c924939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'”ò-* ”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä\\xad–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noiser.add_noise(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b019f",
   "metadata": {},
   "source": [
    "# 2. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f9e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    }
   ],
   "source": [
    "VOCAB = ['‚ñÅ', '[pad]', '[unk]', '[cls]', '[sep]', '[mask]', '[bos]', '[eos]'] + list(all_chars)\n",
    "print(len(VOCAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8fb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_vocab.txt', 'w') as f:\n",
    "    for t in VOCAB:\n",
    "        print(t, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312b8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import char_tokenizer\n",
    "from importlib import reload\n",
    "reload(char_tokenizer)\n",
    "from char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(vocab_file='char_vocab.txt', model_max_length=4092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5920d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertConfig, BertForMaskedLM\n",
    "#from transformers import ReformerConfig, ReformerForMaskedLM  # they don't work, sorry\n",
    "from transformers import LongformerConfig, LongformerForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b454d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = LongformerConfig(\n",
    "    attention_window = 128,\n",
    "    sep_token_id = tokenizer.sep_token_id,\n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    "    bos_token_id = tokenizer.bos_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    vocab_size = len(tokenizer),\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=512,\n",
    "    hidden_act=\"gelu\",\n",
    "    max_position_embeddings = 4096,\n",
    "    position_embedding_type = \"relative_key_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea69e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ecf2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongformerForMaskedLM(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e6fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '../models/longformer-char-ctc-bak-denoise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665ef2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/longformer-char-ctc-bak-denoise\\\\tokenizer_config.json',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\special_tokens_map.json',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\vocab.txt',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b66c54",
   "metadata": {},
   "source": [
    "# 3. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6468b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269ead8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a88c0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "\n",
    "def fix_text(text, verbose=False, spaces=2):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True, return_token_type_ids=False).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ca814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(spaces=1):\n",
    "    dev_small['fixed'] = [fix_text(text, spaces=spaces) for text in dev_small.trash2]\n",
    "    dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "    dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)\n",
    "    return 1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "200079dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.32558139534885"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "564e87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149211e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4048e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_loss = 0\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0df75dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4  # Using a longformer architecture instead of just BERT, allows us increasing the batch size from 3 to 8 w/o OOM\n",
    "\n",
    "share_real = 0.1\n",
    "share_noiser = 0.4\n",
    "p_keep = 0.2\n",
    "\n",
    "report_steps = 1000  \n",
    "cleanup_steps = 100  \n",
    "\n",
    "gradient_steps = 1\n",
    "window = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2521750e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9188345aa3c4605a0e011589148c9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 552000 loss 0.11332793859299273 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "error 552279 sizes: torch.Size([4, 4092]) 5612 / torch.Size([4, 4092]) 5617 CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 432.20 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 553000 loss 0.10836573872971349 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "error 553857 sizes: torch.Size([4, 4092]) 1689 / torch.Size([4, 1681]) 1681 CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 4.00 GiB total capacity; 2.22 GiB already allocated; 170.20 MiB free; 2.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 554000 loss 0.11444802334578708 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "error 554644 sizes: torch.Size([4, 4092]) 5617 / torch.Size([4, 4092]) 5617 CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 402.20 MiB free; 2.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 555000 loss 0.11092352150473744 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 556000 loss 0.11318381068971939 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 557000 loss 0.1089855116060935 error decrease 0.4728682170542635\n",
      "SAVING\n",
      "step 558000 loss 0.1084224740951322 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 559000 loss 0.11184870045888237 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 560000 loss 0.10371085492381826 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 561000 loss 0.10781493211328053 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "error 561367 sizes: torch.Size([4, 4092]) 3187 / torch.Size([4, 3187]) 3187 CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 4.00 GiB total capacity; 2.01 GiB already allocated; 216.20 MiB free; 2.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 562000 loss 0.10683505754871293 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "step 563000 loss 0.10539469715068117 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 564000 loss 0.10036433733347803 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "error 564124 sizes: torch.Size([4, 4092]) 2943 / torch.Size([4, 2947]) 2947 CUDA out of memory. Tried to allocate 370.00 MiB (GPU 0; 4.00 GiB total capacity; 2.01 GiB already allocated; 348.20 MiB free; 2.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 565000 loss 0.10309410429210403 error decrease 0.4883720930232558\n",
      "SAVING\n",
      "step 566000 loss 0.10713950006454252 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 567000 loss 0.11875928560039029 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 568000 loss 0.11002223956398666 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 569000 loss 0.10708022235985845 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 570000 loss 0.09992208153754473 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 571000 loss 0.10833516178536229 error decrease 0.5503875968992248\n",
      "SAVING\n",
      "step 572000 loss 0.09838754585338756 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 573000 loss 0.10577502150135115 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "step 574000 loss 0.09944014067063107 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "error 574522 sizes: torch.Size([4, 4092]) 2588 / torch.Size([4, 2585]) 2585 CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 4.00 GiB total capacity; 2.33 GiB already allocated; 90.20 MiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 575000 loss 0.10322509715892375 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 576000 loss 0.10597850585402921 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 577000 loss 0.1124639516219031 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 578000 loss 0.10313152301497758 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 579000 loss 0.10910690893302671 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "error 579263 sizes: torch.Size([4, 3713]) 1855 / torch.Size([4, 1850]) 1850 CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 4.00 GiB total capacity; 2.43 GiB already allocated; 44.20 MiB free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "error 579940 sizes: torch.Size([4, 4092]) 2342 / torch.Size([4, 2333]) 2333 CUDA out of memory. Tried to allocate 292.00 MiB (GPU 0; 4.00 GiB total capacity; 2.30 GiB already allocated; 140.20 MiB free; 2.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 580000 loss 0.09929613428818994 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "error 580079 sizes: torch.Size([4, 4092]) 2280 / torch.Size([4, 2280]) 2280 CUDA out of memory. Tried to allocate 286.00 MiB (GPU 0; 4.00 GiB total capacity; 2.29 GiB already allocated; 46.20 MiB free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 581000 loss 0.10711868024989962 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 582000 loss 0.10587950887507759 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 583000 loss 0.10023197703389451 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "error 583285 sizes: torch.Size([4, 4092]) 3193 / torch.Size([4, 3187]) 3187 CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 384.20 MiB free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 584000 loss 0.11349487061542458 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "error 584256 sizes: torch.Size([4, 4092]) 3334 / torch.Size([4, 3331]) 3331 CUDA out of memory. Tried to allocate 418.00 MiB (GPU 0; 4.00 GiB total capacity; 2.42 GiB already allocated; 12.20 MiB free; 2.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 585000 loss 0.10607429896923713 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 586000 loss 0.09816942594829016 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 587000 loss 0.10029698877385818 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 588000 loss 0.10067779057379812 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 589000 loss 0.10456094576022587 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 590000 loss 0.09989776321477256 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 591000 loss 0.11392124199913814 error decrease 0.4883720930232558\n",
      "SAVING\n",
      "step 592000 loss 0.09729649633215741 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 593000 loss 0.10051396702881903 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 594000 loss 0.10560183341847733 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 595000 loss 0.10232392276939936 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 596000 loss 0.10449951965967193 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 597000 loss 0.1046480629381258 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 598000 loss 0.09754875400126911 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 599000 loss 0.1030397566985339 error decrease 0.49612403100775193\n",
      "SAVING\n"
     ]
    }
   ],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "cleanup()\n",
    "model.train()\n",
    "\n",
    "tq = trange(len(losses), 600_000)\n",
    "for i in tq:\n",
    "    r = random.random()\n",
    "    if r < share_real:\n",
    "        batch = df_orig_train.sample(batch_size)\n",
    "        xx, yy = batch.trash2.tolist(), batch.clean2.tolist()\n",
    "    elif r < share_real + share_noiser:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [noiser.add_noise(text, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    else:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [add_simple_noise(text, all_chars, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    \n",
    "    random_spaces = random.choices([0, 1, 2], weights=[0.1, 0.7, 0.2])[0]\n",
    "    batch = tokenizer(xx, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True).to(model.device)\n",
    "    batch_labels = tokenizer(yy, return_tensors='pt', spaces=0, padding=True, truncation=True, add_special_tokens=False).to(model.device)\n",
    "\n",
    "    try:\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "        loss = torch.nn.functional.ctc_loss(\n",
    "            logits.transpose(1, 0), \n",
    "            batch_labels.input_ids, \n",
    "            batch.attention_mask.sum(1), \n",
    "            batch_labels.attention_mask.sum(1), \n",
    "            reduction='mean',\n",
    "            zero_infinity=True,\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        if i % gradient_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' not in str(e):\n",
    "            raise e\n",
    "        print(\n",
    "            'error', i, \n",
    "            'sizes:', batch['input_ids'].shape, max(len(_) for _ in xx), \n",
    "            '/', batch_labels['input_ids'].shape, max(len(_) for _ in yy), \n",
    "            e\n",
    "        )\n",
    "        # raise e\n",
    "        loss, logits, batch, batch_labels = None, None, None, None\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        cleanup()\n",
    "        continue\n",
    "\n",
    "    w = 1 / max(1, min(len(losses), window))\n",
    "    ewm_loss = ewm_loss * (1-w) + loss.item() * w\n",
    "    losses.append(loss.item())\n",
    "    tq.set_description(f'{ewm_loss:3.3f}')\n",
    "\n",
    "    if len(losses) % report_steps == 0:\n",
    "        model.eval();\n",
    "        print('step', len(losses), 'loss', np.mean(losses[-report_steps:]), 'error decrease', eval_model())\n",
    "        model.train();\n",
    "        if i > 0:\n",
    "            print('SAVING')\n",
    "            model.save_pretrained(MODEL_NAME)\n",
    "            tokenizer.save_pretrained(MODEL_NAME)\n",
    "    if i % cleanup_steps == 0:\n",
    "        cleanup()\n",
    "    # implement a very late learning rate cooldown\n",
    "    if i >= 460_000:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-4 * (600_000 - i) / (600_000 - 460_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f4d3cc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# step 149000 loss 0.14386079168878496 error decrease 0.3875968992248062\n",
    "# At 460000 steps I accidentially broke the model, by using a x10 larger learning rate than I should have.\n",
    "pd.Series(losses).ewm(3000).mean()[10_000:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c50167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(xx, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144281ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_index_global_attn = batch.attention_mask > 0\n",
    "is_global_attn = is_index_global_attn.flatten().any().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_global_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d02ac070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85e50f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21090464780542a3970acd4b037b2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_small['fixed'] = [fix_text(text, 1) for text in tqdm(dev_small.trash2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af5af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "69987454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance               1.2900\n",
       "normalized_distance    0.0175\n",
       "edit_max_cldiff        0.4600\n",
       "edit_max_lendiff       0.0300\n",
       "change_amount          0.8800\n",
       "new_diff               0.6300\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b0cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5116279069767442"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ba0fb",
   "metadata": {},
   "source": [
    "In the end, the gains seem to be not as good as with a normal BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a3358d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49612403100775193\n",
      "0.49612403100775193\n",
      "0.5116279069767442\n"
     ]
    }
   ],
   "source": [
    "for s in range(3):\n",
    "    print(eval_model(spaces=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "187dd527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä\\xad–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "761bcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(text, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True).to(model.device)\n",
    "with torch.no_grad():\n",
    "    logits = torch.log_softmax(model(**batch).logits, axis=-1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e248d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 115, 395])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f23808",
   "metadata": {},
   "source": [
    "This beam decoder works, but it is slow as fuck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97c96204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "def decode_ctc_beam(log_proba, num_beams=10, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(0))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    for step in trange(log_proba.shape[0]):\n",
    "        hyp2logscores = defaultdict(list)\n",
    "        for token_id in range(log_proba.shape[1]):\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score + log_proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    hyp2logscores[(seq, False)].append(new_score)\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        hyp2logscores[(seq, True)].append(new_score)\n",
    "                    else:\n",
    "                        hyp2logscores[(seq + (token_id,), True)].append(new_score)\n",
    "        scorer = Counter()\n",
    "        for k, scores in hyp2logscores.items():\n",
    "            scorer[k] = torch.logsumexp(torch.stack(scores), 0)\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return beams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737e079",
   "metadata": {},
   "source": [
    "Speed up by moving into the probabilities space: better, but still fuking slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "01af3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_beam(log_proba, num_beams=10, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(1))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    proba = torch.softmax(log_proba, -1)\n",
    "    for step in trange(log_proba.shape[0]):\n",
    "        scorer = Counter()\n",
    "        for token_id in range(log_proba.shape[1]):\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score * proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    scorer[(seq, False)] += new_score\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        scorer[(seq, True)] += new_score\n",
    "                    else:\n",
    "                        scorer[(seq + (token_id,), True)] += new_score\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f828b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_beam(log_proba, num_beams=10, n2=11, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(1))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    proba = torch.softmax(log_proba, -1)\n",
    "    for step in range(log_proba.shape[0]):\n",
    "        scorer = Counter()\n",
    "        _, indices = torch.topk(proba[step], n2)\n",
    "        for token_id in indices.cpu().numpy():\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score * proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    scorer[(seq, False)] += new_score\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        scorer[(seq, True)] += new_score\n",
    "                    else:\n",
    "                        scorer[(seq + (token_id,), True)] += new_score\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return [(seq, score.item()) for (seq, is_open, score) in beams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b9d780b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832899808883667 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?\n",
      "0.035917624831199646 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, - —Ç–∏“ª–µ“£–º–µ?\n",
      "0.007658788003027439 ”ò ”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?\n",
      "0.005061058793216944 ”ò-”ô, —É–ª–∞—Ä “ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?\n",
      "0.003933039028197527 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”© —Ç–∏“ª–µ“£–º–µ?\n"
     ]
    }
   ],
   "source": [
    "beams = decode_ctc_beam(logits[0], n2=20)\n",
    "for hyp, score in beams[:5]:\n",
    "    print(score, ''.join(tokenizer.convert_ids_to_tokens(hyp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "363fbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8234241008758545 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ?\n",
      "0.03550899028778076 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, - —Ç–∏“ª–µ“£–º–µ?\n",
      "0.0038908934220671654 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”© —Ç–∏“ª–µ“£–º–µ?\n",
      "0.0016263878205791116 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏“ª–µ“£–º–µ.\n",
      "0.001475932658649981 ”ò-”ô, —É–ª–∞—Ä“ô–∞ —Ç–æ—Ä–º–æ—à –∏–∫–µ–Ω—Å–µ, —Ç”ô—Ä¬≠–±–∏”ô –±–∞—à“°–∞ —Ç”©—Ä–ª”©, —Ç–∏h–µ“£–º–µ?\n"
     ]
    }
   ],
   "source": [
    "beams = decode_ctc_beam(logits[0], num_beams=5, n2=5)\n",
    "for hyp, score in beams[:5]:\n",
    "    print(score, ''.join(tokenizer.convert_ids_to_tokens(hyp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c113218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_text_beam(text, verbose=False, spaces=1, num_beams=5, num_top=5):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True, return_token_type_ids=False).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    if num_beams <= 1:\n",
    "        return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)\n",
    "    hyps = decode_ctc_beam(logits[0], num_beams=num_beams, n2=num_top)\n",
    "    return tokenizer.decode(hyps[0][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cc643973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19405475f4e4cdf9314c2d5cbe31e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_small['fixed'] = [fix_text_beam(text, spaces=1, num_beams=5, num_top=3) for text in tqdm(dev_small.trash2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4c846455",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69987454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance               1.2900\n",
       "normalized_distance    0.0175\n",
       "edit_max_cldiff        0.4600\n",
       "edit_max_lendiff       0.0300\n",
       "change_amount          1.6600\n",
       "new_diff               1.3500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8b0cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04651162790697683"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "97c480d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19699                                                                                                                                                  –î–µ–ª–∞–≥–æ–∞ “°—É–ª—Ç—ã“ì—ã–Ω–¥–∞.\n",
       "965                                                            –î–∏—É–∞—Ä“ô–∞—Ä –±—É–π–ª–∞–ø –±–µ—Ä ”©“´–∫”ô, –±–µ—Ä –∞“´“°–∞ –∫“Ø—Å–µ–ø, –∏“£ ”©“´–∫”© “°–∞—Ç–∞—Ä“ô–∞“ì—ã ”©–π —ç—Å—Ç”ô—Ä–µ–Ω, –∑–∞–ª–¥–∞—Ä“ô—ã, —Å–∞—Ä“ô–∞“°—Ç–∞—Ä“ô—ã “°–∞—Ä–∞–ø —Å—ã“°—Ç—ã–º.\n",
       "13577                                                                                                            “Æ“ô-–∞—Ä–∞ —Å”ô“£–≥–µ–ª–¥”ô—à–µ–ø: - –ô”©—Ä”©–π —à—É–Ω–¥–∞, “°–∞—Ä—Ç–∞–π“ì–∞–Ω–¥–∞ —Ç—ã—Ä—Ç–∞–π“ì–∞–Ω!\n",
       "12487                                                                                                                                            “†–æ—Ä–±–∞–Ω“ì”ô–ª–µ, “ª–∏“£”ô ”ô–π—Ç”ô–º—Å–µ.\n",
       "20720                                                                     –û—à–æ “ª“Ø“ô”ô–Ω “ª—É“£ —É–Ω—ã“£ —Ç–∞—É—ã—à—ã ”©“ô”©–ª–¥”©, “ª”ô–º —É–ª, –Ω–∏—Å–µ–∫ —Ç–æ—Ä“ª–∞ - —à—É–ª –∫–∏–ª–µ—à, –±”©—Ç”ô –∞—è“°—Ç–∞—Ä—ã –º–µ–Ω”ô–Ω –µ—Ä–≥”ô –∞—É“ô—ã.\n",
       "                                                                                       ...                                                                                \n",
       "23813                                                                          –ö–∞–∑–∞“ì–∞ —Ç–∞—Ä—ã“°–∞–Ω –æ—à–æ –∫–∞—Ä—É–∞–Ω“ì–∞ —é–ª –±–µ–ª–µ“Ø—Å–µ –±–µ—Ä —é–ª–∞–º–∞–Ω —Ç–∞–ø –±—É–ª—ã–ø, —É–Ω—ã “ª—ã—É —è–Ω—ã–Ω–∞ –∞–ª—ã–ø –∫–∏–ª–≥”ô–Ω, —Ç–∏.\n",
       "8808     –ö–µ—à–µ“ª–µ“ô —Ç—ã–ø-—Ç—ã–Ω —é–ª–¥–∞ —à—É–ª–∞–π –º–æ“£ —Å”ô—Å–µ–ø –±–∞—Ä—ã—É—ã–Ω—ã“£, “Ø“ô “ª—ã—É“ª—ã–Ω—ã–Ω “ì—ã–Ω–∞ “°–∞–Ω–¥—ã—Ä—ã–ø “°–∞–ª–º–∞–π—ã–Ω—Å–∞, –∞—Ç–∞“ª—ã–Ω–∞ –ª–∞ ”ô–ª”ô –Ω–∏ —Ö”ô—Ç–ª–µ–º –∏–ª–∞“ª–∏ –±–µ—Ä —Ä”ô—Ö”ô—Ç–ª–µ–∫ –±–∏—Ä–µ“Ø–µ–Ω –±–µ–ª”ô–º–µ –∏–∫”ô–Ω –¢”©–ª–∫”©—Å—É—Ä–∞?.\n",
       "5764                                                                                                      –î–∏“£–≥–µ“ô–µ –∫”©–Ω–¥”©“ô “Ø–∫ –∞“° –∫“Ø–±–µ–∫”ô –º–∞–Ω“ì–∞–Ω –µ–ª —Ç–∞“ì—ã –ª–∞ –∫”©—Å”ô–π”ô –∏–Ω–µ —à–∏–∫–µ–ª–µ.\n",
       "1923                                                                                                 –¢–µ–≥–µ –∫–µ—à–µ —à”ô–ø—à”ô–ø –∞—Ç–ª–∞–ø –∞—Ä—ã –∫–∏—Ç–µ–ø –±–∞—Ä–∞; —ç—Ä–≥”ô-—Ç–∏—Ä”ô–ª”ô –±–∞—à“°–∞ –±–µ—Ä”ô“Ø “ô”ô —é“°.\n",
       "5144                                                               –£–ª–∞—Ä –∞“ì–∞“ª—ã, –µ“£–≥”ô“ª–µ, —É–ª–∞—Ä“ô—ã“£ –±–µ—Ä –π”ô—à–ª–µ–∫ –∫–µ–Ω”ô —É–ª–¥–∞—Ä—ã –°–∞–ª–∞—É–∞—Ç –¥“Ø—Ä—Ç”ô“Ø–ª”ô–ø, –°”ô–ª–∏–º”ô –º”ô—Ä—Ö“Ø–º–¥–µ“£ ”©–π”©–Ω–¥”ô –π”ô—à”ô–π“ô”ô—Ä.\n",
       "Name: fixed, Length: 100, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small['fixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a39b1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aacf463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean2</th>\n",
       "      <th>fixed</th>\n",
       "      <th>new_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>–£–ª–∞—Ä –±–∞—à–ª—ã—Å–∞ –£—Ä–∞–ª –∞—Ä—ä—è“ì—ã–Ω–¥–∞ –∫“Ø–±”ô–π”ô –±–∞—Ä“ì–∞–Ω –∏–≥–µ–Ω –∏–≥–µ“Ø—Å–µ –∞—É—ã–ª–¥–∞—Ä“ô–∞–Ω –π—ã–π—ã–ª“ì–∞–π–Ω—ã. ...–¢”©–ª–∫”©—Å—É—Ä–∞ “Ø“ô–µ–Ω”ô –π—ã–ª“ì–∞–Ω—ã “°–∞–π“ô–∞–Ω –∫–∏—Å–µ“Ø –∫”ô—Ä”ô–∫–ª–µ–≥–µ–Ω –∫“Ø—Ä“ª”ô—Ç–∫”ô–Ω –±–∏–ª–¥”ô–ª”ô—Ä“ô–µ –∞–ª—ã“´—Ç–∞–Ω —É“° –∞–±–∞–π–ª–∞–ø –∫–∏–ª–¥–µ.</td>\n",
       "      <td>–£–ª–∞—Ä –±–∞—à–ª—ã—Å–∞ –£—Ä–∞–ª –∞—Ä—ä—è“ì—ã–Ω–¥–∞ –∫“Ø–±”ô–π”ô –±–∞—Ä“ì–∞–Ω –∏–≥–µ–Ω –∏—Ç–µ“Ø—Å–µ –∞—É—ã–ª–¥–∞—Ä“ô–∞–Ω –π—ã–π—ã–ª“ì–∞–π–Ω—ã. .–¢”©–ª–∫”©—Å—É—Ä–∞ “Ø“ô–µ–Ω”ô –π—ã–ª“ì–∞–Ω—ã “°–∞–π“ô–∞–Ω –∫–∏—Å–µ“Ø –∫”ô—Ä”ô–∫–ª–µ–≥–µ–Ω –∫“Ø—Ä“ª”ô—Ç–∫”ô–Ω –±–∏–ª–¥”ô–ª”ô—Ä“ô–µ –∞–ª—ã“´—Ç–∞–Ω —É“° –∞–±–∞–π–ª–∞–ø –∫–∏–ª–¥–µ.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>“†–∞–∑–∞“ì–∞ —Ç–∞—Ä—ã“°“°–∞–Ω –æ—à–æ –∫–∞—Ä—É–∞–Ω“ì–∞ —é–ª –±–µ–ª–µ“Ø—Å–µ –±–µ—Ä —é–ª–∞–º–∞–Ω —Ç–∞–ø –±—É–ª—ã–ø, —É–Ω—ã “ª—ã—É —è–Ω—ã–Ω–∞ –∞–ª—ã–ø –∫–∏–ª–≥”ô–Ω, —Ç–∏.</td>\n",
       "      <td>–ö–∞–∑–∞“ì–∞ —Ç–∞—Ä—ã“°–∞–Ω –æ—à–æ –∫–∞—Ä—É–∞–Ω“ì–∞ —é–ª –±–µ–ª–µ“Ø—Å–µ –±–µ—Ä —é–ª–∞–º–∞–Ω —Ç–∞–ø –±—É–ª—ã–ø, —É–Ω—ã “ª—ã—É —è–Ω—ã–Ω–∞ –∞–ª—ã–ø –∫–∏–ª–≥”ô–Ω, —Ç–∏.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>–ë—ã—É–∞ –π—ã–ª“ì–∞–Ω—ã“£ “ª–∞–π “ì—ã–Ω–∞ —Å–∏—Ç–µ–Ω–¥”ô - “°—ã—Ä—Å—ã–Ω–ª—ã“°—Ç–∞ –∏–Ω–µ.</td>\n",
       "      <td>–ë—ã—É–∞ –π—ã–ª“ì–∞–Ω—ã“£ “ª–∞–π “ì—ã–Ω–∞ —Å–∏—Ç–µ–Ω–¥”ô “°—ã—Ä—Å—ã–Ω–ª—ã“°—Ç–∞ –∏–Ω–µ.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               clean2  \\\n",
       "15073  –£–ª–∞—Ä –±–∞—à–ª—ã—Å–∞ –£—Ä–∞–ª –∞—Ä—ä—è“ì—ã–Ω–¥–∞ –∫“Ø–±”ô–π”ô –±–∞—Ä“ì–∞–Ω –∏–≥–µ–Ω –∏–≥–µ“Ø—Å–µ –∞—É—ã–ª–¥–∞—Ä“ô–∞–Ω –π—ã–π—ã–ª“ì–∞–π–Ω—ã. ...–¢”©–ª–∫”©—Å—É—Ä–∞ “Ø“ô–µ–Ω”ô –π—ã–ª“ì–∞–Ω—ã “°–∞–π“ô–∞–Ω –∫–∏—Å–µ“Ø –∫”ô—Ä”ô–∫–ª–µ–≥–µ–Ω –∫“Ø—Ä“ª”ô—Ç–∫”ô–Ω –±–∏–ª–¥”ô–ª”ô—Ä“ô–µ –∞–ª—ã“´—Ç–∞–Ω —É“° –∞–±–∞–π–ª–∞–ø –∫–∏–ª–¥–µ.   \n",
       "23813                                                                                    “†–∞–∑–∞“ì–∞ —Ç–∞—Ä—ã“°“°–∞–Ω –æ—à–æ –∫–∞—Ä—É–∞–Ω“ì–∞ —é–ª –±–µ–ª–µ“Ø—Å–µ –±–µ—Ä —é–ª–∞–º–∞–Ω —Ç–∞–ø –±—É–ª—ã–ø, —É–Ω—ã “ª—ã—É —è–Ω—ã–Ω–∞ –∞–ª—ã–ø –∫–∏–ª–≥”ô–Ω, —Ç–∏.   \n",
       "15509                                                                                                                               –ë—ã—É–∞ –π—ã–ª“ì–∞–Ω—ã“£ “ª–∞–π “ì—ã–Ω–∞ —Å–∏—Ç–µ–Ω–¥”ô - “°—ã—Ä—Å—ã–Ω–ª—ã“°—Ç–∞ –∏–Ω–µ.   \n",
       "\n",
       "                                                                                                                                                                              fixed  \\\n",
       "15073  –£–ª–∞—Ä –±–∞—à–ª—ã—Å–∞ –£—Ä–∞–ª –∞—Ä—ä—è“ì—ã–Ω–¥–∞ –∫“Ø–±”ô–π”ô –±–∞—Ä“ì–∞–Ω –∏–≥–µ–Ω –∏—Ç–µ“Ø—Å–µ –∞—É—ã–ª–¥–∞—Ä“ô–∞–Ω –π—ã–π—ã–ª“ì–∞–π–Ω—ã. .–¢”©–ª–∫”©—Å—É—Ä–∞ “Ø“ô–µ–Ω”ô –π—ã–ª“ì–∞–Ω—ã “°–∞–π“ô–∞–Ω –∫–∏—Å–µ“Ø –∫”ô—Ä”ô–∫–ª–µ–≥–µ–Ω –∫“Ø—Ä“ª”ô—Ç–∫”ô–Ω –±–∏–ª–¥”ô–ª”ô—Ä“ô–µ –∞–ª—ã“´—Ç–∞–Ω —É“° –∞–±–∞–π–ª–∞–ø –∫–∏–ª–¥–µ.   \n",
       "23813                                                                                   –ö–∞–∑–∞“ì–∞ —Ç–∞—Ä—ã“°–∞–Ω –æ—à–æ –∫–∞—Ä—É–∞–Ω“ì–∞ —é–ª –±–µ–ª–µ“Ø—Å–µ –±–µ—Ä —é–ª–∞–º–∞–Ω —Ç–∞–ø –±—É–ª—ã–ø, —É–Ω—ã “ª—ã—É —è–Ω—ã–Ω–∞ –∞–ª—ã–ø –∫–∏–ª–≥”ô–Ω, —Ç–∏.   \n",
       "15509                                                                                                                               –ë—ã—É–∞ –π—ã–ª“ì–∞–Ω—ã“£ “ª–∞–π “ì—ã–Ω–∞ —Å–∏—Ç–µ–Ω–¥”ô “°—ã—Ä—Å—ã–Ω–ª—ã“°—Ç–∞ –∏–Ω–µ.   \n",
       "\n",
       "       new_diff  \n",
       "15073         3  \n",
       "23813         2  \n",
       "15509         2  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small[['clean2', 'fixed', 'new_diff']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7e96d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '–£–Ω—ã –∞–ª—ã–ø –±–∞—Ä—ã–ø “°—É—à“°–∞–Ω –∫–µ—à–µ–ª”ô—Ä —Ç”©—Ä–∫”©–º”©–Ω–¥”ô –ì–µ—Ä–∞—Ä–¥-—Ç—É“ì–∞–Ω –¥–∞ –±–∞—Ä –∏–Ω–µ, —É–ª –∏–Ω–¥–µ –±–∞—Ä—ã“ª—ã–Ω “ª–æ—Ä–∞—à—ã–ø-–±–µ–ª–µ–ø ”©–ª–≥”©—Ä–≥”ô–π–Ω–µ.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5ac38dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=1, num_top=1) == fix_text(text, spaces=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8cc50dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–£–Ω—ã –∞–ª—ã–ø –±–∞—Ä—ã–ø “°—É—à“°–∞–Ω –∫–µ—à–µ–ª”ô—Ä —Ç”©—Ä–∫”©–º”©–Ω–¥”ô –ì–µ—Ä–∞—Ä–¥-—Ç—É“ì–∞–Ω –¥–∞ –±–∞—Ä –∏–Ω–µ, —É–ª –∏–Ω–¥–µ –±–∞—Ä—ã“ª—ã–Ω “ª–æ—Ä–∞—à—ã–ø-–±–µ–ª–µ–ø ”©–ª–≥”©—Ä–≥”ô–π–Ω–µ.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=1, num_top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6a5cbc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–£–Ω—ã –∞–ª—ã–ø –±–∞—Ä—ã–ø “°—É—à“°–∞–Ω –∫–µ—à–µ–ª”ô—Ä —Ç”©—Ä–∫”©–º”©–Ω–¥”ô –ì–µ—Ä–∞—Ä–¥-—Ç—É“ì–∞–Ω –¥–∞ –±–∞—Ä –∏–Ω–µ, —É–ª –∏–Ω–¥–µ –±–∞—Ä—ã“ª—ã–Ω “ª–æ—Ä–∞—à—ã–ø-–±–µ–ª–µ–ø ”©–ª–≥”©—Ä–≥”ô–π–Ω–µ.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=5, num_top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f029ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
