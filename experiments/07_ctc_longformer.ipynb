{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f75b144",
   "metadata": {},
   "source": [
    "The same idea as in the Notebook 6, but with a more efficient model architecture: https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/reformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f6e47",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fc96a",
   "metadata": {},
   "source": [
    "## 1. 1. Load the parallel text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaffe14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trash</th>\n",
       "      <th>clean</th>\n",
       "      <th>trash2</th>\n",
       "      <th>clean2</th>\n",
       "      <th>distance</th>\n",
       "      <th>normalized_distance</th>\n",
       "      <th>split</th>\n",
       "      <th>edit_max_cldiff</th>\n",
       "      <th>edit_max_lendiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Минең генә бер кешем дә юҡ, тип шунда уҡ танау...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, тип шунда уҡ танау...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23886</th>\n",
       "      <td>Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23887</th>\n",
       "      <td>Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23890</th>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   trash  \\\n",
       "0      Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, тип шунда уҡ танау...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...   \n",
       "23888  Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...   \n",
       "\n",
       "                                                   clean  \\\n",
       "0      Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...   \n",
       "23888  Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...   \n",
       "\n",
       "                                                  trash2  \\\n",
       "0      Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, тип шунда уҡ танау...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...   \n",
       "23888  Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...   \n",
       "\n",
       "                                                  clean2  distance  \\\n",
       "0      Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...         1   \n",
       "1            Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.         3   \n",
       "2      «Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...         1   \n",
       "3      Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...         2   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...         1   \n",
       "...                                                  ...       ...   \n",
       "23886  Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...         1   \n",
       "23887  Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...         1   \n",
       "23888  Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...         1   \n",
       "23889  Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...         1   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...         2   \n",
       "\n",
       "       normalized_distance  split  edit_max_cldiff  edit_max_lendiff  \n",
       "0                 0.015385  train                1                 0  \n",
       "1                 0.069767   test                1                 0  \n",
       "2                 0.014085    dev                1                 0  \n",
       "3                 0.029412  train                0                 0  \n",
       "4                 0.012500  train                1                 0  \n",
       "...                    ...    ...              ...               ...  \n",
       "23886             0.020000    dev                1                 0  \n",
       "23887             0.009524  train                1                 0  \n",
       "23888             0.020000  train                1                 0  \n",
       "23889             0.009174  train                1                 0  \n",
       "23890             0.021053  train                0                 0  \n",
       "\n",
       "[23891 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv('../data/spellchecker_dataset_split.tsv', sep='\\t')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b03813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14382, 9)\n",
      "(14171, 9)\n",
      "(14085, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_train = df_orig[(df_orig.split=='train')]\n",
    "print(df_orig_train.shape)\n",
    "\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_cldiff <= 3]\n",
    "print(df_orig_train.shape)\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_lendiff <= 1].copy()\n",
    "print(df_orig_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5f5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4611, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_dev = df_orig[(df_orig.split=='dev') & (df_orig.edit_max_cldiff <= 3) & (df_orig.edit_max_lendiff <= 1)]\n",
    "print(df_orig_dev.shape)\n",
    "dev_small = df_orig_dev.sample(100, random_state=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154994",
   "metadata": {},
   "source": [
    "## 1.2. Corrupt the clean sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851b9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605495\n"
     ]
    }
   ],
   "source": [
    "with open('../data/clean_bk_sents.txt', 'r') as f:\n",
    "    cs2 = [line.strip() for line in f]\n",
    "print(len(cs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ba88fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¢¦§ª«¬­®°²µ·»¿ÀÁÂÄÉÊÌÍÎÐÒÖ×ØÜÝÞàáâãäåçèéêëìíîïðñòóôõö÷øûüýÿāČčğıłŠšūŽžƏəɵʺ̶́ΒΠΧЁЃЄЅІЉЋЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёђѓєѕіїљњћќўџѲѳҐҒғҖҗҘҙқҠҡҢңҪҫҮүҰҺһӊӘәӧӨөاتخرسعكنو  ​‎‐‑‒–—―‘’“”„•… ‰›⁠№Ⅰ→∂−≥⏰─●☎⚡✒✓✨﻿🌸🎭📝\n",
      "354\n",
      "\t !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¢¦§ª«¬­®°²µ·»¿ÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÛÜÝÞàáâãäåçèéêëìíîïðñòóôõö÷øûüýþÿĀāČčĞğıŁłŠšŪūŸŽžƏƟəɵʺ̶́ΒΜΠΧβπχЁЂЃЄЅІЇЉЊЋЌЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёђѓєѕіїљњћќўџѲѳҐґҒғҖҗҘҙҚқҠҡҢңҪҫҮүҰұҺһӉӊӘәӦӧӨөاتخرسعكنو  ​‎‐‑‒–—―‘’“”„•… ‰›⁠№Ⅰⅰ→∂−≥⏰─●☎⚡✒✓✨﻿🌸🎭📝\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "all_chars = ''.join(sorted({\n",
    "    c for texts in [cs2, df_orig_train.trash, df_orig_train.clean] \n",
    "    for text in texts for c in text\n",
    "}))\n",
    "print(all_chars)\n",
    "print(len(all_chars))\n",
    "\n",
    "all_chars = ''.join(sorted(set(all_chars + all_chars.upper() + all_chars.lower())))\n",
    "print(all_chars)\n",
    "print(len(all_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3120603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisers import add_simple_noise\n",
    "from noisers import Noiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e058f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = Noiser.load('noise_model_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd24e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ә-ә, уларҙа тормош икенсе, тәр\\xadбиә башҡа төрлө, тиһеңме?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = random.choice(cs2)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797922d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ә-ә, уларҙа тормош икенсÂе, әр\\xadбиә бɵшҡа төрлө, тиһеJме?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_simple_noise(text, all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c924939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ә-* ә, уларҙа тормош икенсе, тәр\\xadбиә башҡа төрлө, тиһеңме?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noiser.add_noise(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b019f",
   "metadata": {},
   "source": [
    "# 2. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f9e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    }
   ],
   "source": [
    "VOCAB = ['▁', '[pad]', '[unk]', '[cls]', '[sep]', '[mask]', '[bos]', '[eos]'] + list(all_chars)\n",
    "print(len(VOCAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8fb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_vocab.txt', 'w') as f:\n",
    "    for t in VOCAB:\n",
    "        print(t, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312b8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import char_tokenizer\n",
    "from importlib import reload\n",
    "reload(char_tokenizer)\n",
    "from char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(vocab_file='char_vocab.txt', model_max_length=4092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5920d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertConfig, BertForMaskedLM\n",
    "#from transformers import ReformerConfig, ReformerForMaskedLM  # they don't work, sorry\n",
    "from transformers import LongformerConfig, LongformerForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b454d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = LongformerConfig(\n",
    "    attention_window = 128,\n",
    "    sep_token_id = tokenizer.sep_token_id,\n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    "    bos_token_id = tokenizer.bos_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    vocab_size = len(tokenizer),\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=512,\n",
    "    hidden_act=\"gelu\",\n",
    "    max_position_embeddings = 4096,\n",
    "    position_embedding_type = \"relative_key_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea69e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ecf2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongformerForMaskedLM(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e6fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '../models/longformer-char-ctc-bak-denoise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665ef2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/longformer-char-ctc-bak-denoise\\\\tokenizer_config.json',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\special_tokens_map.json',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\vocab.txt',\n",
       " '../models/longformer-char-ctc-bak-denoise\\\\added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b66c54",
   "metadata": {},
   "source": [
    "# 3. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6468b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269ead8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a88c0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "\n",
    "def fix_text(text, verbose=False, spaces=2):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True, return_token_type_ids=False).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ca814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(spaces=1):\n",
    "    dev_small['fixed'] = [fix_text(text, spaces=spaces) for text in dev_small.trash2]\n",
    "    dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "    dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)\n",
    "    return 1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "200079dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.32558139534885"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "564e87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149211e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4048e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_loss = 0\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0df75dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4  # Using a longformer architecture instead of just BERT, allows us increasing the batch size from 3 to 8 w/o OOM\n",
    "\n",
    "share_real = 0.1\n",
    "share_noiser = 0.4\n",
    "p_keep = 0.2\n",
    "\n",
    "report_steps = 1000  \n",
    "cleanup_steps = 100  \n",
    "\n",
    "gradient_steps = 1\n",
    "window = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2521750e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9188345aa3c4605a0e011589148c9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 552000 loss 0.11332793859299273 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "error 552279 sizes: torch.Size([4, 4092]) 5612 / torch.Size([4, 4092]) 5617 CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 432.20 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 553000 loss 0.10836573872971349 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "error 553857 sizes: torch.Size([4, 4092]) 1689 / torch.Size([4, 1681]) 1681 CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 4.00 GiB total capacity; 2.22 GiB already allocated; 170.20 MiB free; 2.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 554000 loss 0.11444802334578708 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "error 554644 sizes: torch.Size([4, 4092]) 5617 / torch.Size([4, 4092]) 5617 CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 402.20 MiB free; 2.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 555000 loss 0.11092352150473744 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 556000 loss 0.11318381068971939 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 557000 loss 0.1089855116060935 error decrease 0.4728682170542635\n",
      "SAVING\n",
      "step 558000 loss 0.1084224740951322 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 559000 loss 0.11184870045888237 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 560000 loss 0.10371085492381826 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 561000 loss 0.10781493211328053 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "error 561367 sizes: torch.Size([4, 4092]) 3187 / torch.Size([4, 3187]) 3187 CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 4.00 GiB total capacity; 2.01 GiB already allocated; 216.20 MiB free; 2.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 562000 loss 0.10683505754871293 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "step 563000 loss 0.10539469715068117 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 564000 loss 0.10036433733347803 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "error 564124 sizes: torch.Size([4, 4092]) 2943 / torch.Size([4, 2947]) 2947 CUDA out of memory. Tried to allocate 370.00 MiB (GPU 0; 4.00 GiB total capacity; 2.01 GiB already allocated; 348.20 MiB free; 2.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 565000 loss 0.10309410429210403 error decrease 0.4883720930232558\n",
      "SAVING\n",
      "step 566000 loss 0.10713950006454252 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 567000 loss 0.11875928560039029 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 568000 loss 0.11002223956398666 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 569000 loss 0.10708022235985845 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 570000 loss 0.09992208153754473 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 571000 loss 0.10833516178536229 error decrease 0.5503875968992248\n",
      "SAVING\n",
      "step 572000 loss 0.09838754585338756 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 573000 loss 0.10577502150135115 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "step 574000 loss 0.09944014067063107 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "error 574522 sizes: torch.Size([4, 4092]) 2588 / torch.Size([4, 2585]) 2585 CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 4.00 GiB total capacity; 2.33 GiB already allocated; 90.20 MiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 575000 loss 0.10322509715892375 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 576000 loss 0.10597850585402921 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 577000 loss 0.1124639516219031 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "step 578000 loss 0.10313152301497758 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 579000 loss 0.10910690893302671 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "error 579263 sizes: torch.Size([4, 3713]) 1855 / torch.Size([4, 1850]) 1850 CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 4.00 GiB total capacity; 2.43 GiB already allocated; 44.20 MiB free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "error 579940 sizes: torch.Size([4, 4092]) 2342 / torch.Size([4, 2333]) 2333 CUDA out of memory. Tried to allocate 292.00 MiB (GPU 0; 4.00 GiB total capacity; 2.30 GiB already allocated; 140.20 MiB free; 2.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 580000 loss 0.09929613428818994 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "error 580079 sizes: torch.Size([4, 4092]) 2280 / torch.Size([4, 2280]) 2280 CUDA out of memory. Tried to allocate 286.00 MiB (GPU 0; 4.00 GiB total capacity; 2.29 GiB already allocated; 46.20 MiB free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 581000 loss 0.10711868024989962 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 582000 loss 0.10587950887507759 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 583000 loss 0.10023197703389451 error decrease 0.5271317829457365\n",
      "SAVING\n",
      "error 583285 sizes: torch.Size([4, 4092]) 3193 / torch.Size([4, 3187]) 3187 CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 4.00 GiB total capacity; 2.02 GiB already allocated; 384.20 MiB free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 584000 loss 0.11349487061542458 error decrease 0.5348837209302326\n",
      "SAVING\n",
      "error 584256 sizes: torch.Size([4, 4092]) 3334 / torch.Size([4, 3331]) 3331 CUDA out of memory. Tried to allocate 418.00 MiB (GPU 0; 4.00 GiB total capacity; 2.42 GiB already allocated; 12.20 MiB free; 2.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "step 585000 loss 0.10607429896923713 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 586000 loss 0.09816942594829016 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 587000 loss 0.10029698877385818 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 588000 loss 0.10067779057379812 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 589000 loss 0.10456094576022587 error decrease 0.5193798449612403\n",
      "SAVING\n",
      "step 590000 loss 0.09989776321477256 error decrease 0.5116279069767442\n",
      "SAVING\n",
      "step 591000 loss 0.11392124199913814 error decrease 0.4883720930232558\n",
      "SAVING\n",
      "step 592000 loss 0.09729649633215741 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 593000 loss 0.10051396702881903 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 594000 loss 0.10560183341847733 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 595000 loss 0.10232392276939936 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 596000 loss 0.10449951965967193 error decrease 0.5038759689922481\n",
      "SAVING\n",
      "step 597000 loss 0.1046480629381258 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 598000 loss 0.09754875400126911 error decrease 0.49612403100775193\n",
      "SAVING\n",
      "step 599000 loss 0.1030397566985339 error decrease 0.49612403100775193\n",
      "SAVING\n"
     ]
    }
   ],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "cleanup()\n",
    "model.train()\n",
    "\n",
    "tq = trange(len(losses), 600_000)\n",
    "for i in tq:\n",
    "    r = random.random()\n",
    "    if r < share_real:\n",
    "        batch = df_orig_train.sample(batch_size)\n",
    "        xx, yy = batch.trash2.tolist(), batch.clean2.tolist()\n",
    "    elif r < share_real + share_noiser:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [noiser.add_noise(text, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    else:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [add_simple_noise(text, all_chars, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    \n",
    "    random_spaces = random.choices([0, 1, 2], weights=[0.1, 0.7, 0.2])[0]\n",
    "    batch = tokenizer(xx, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True).to(model.device)\n",
    "    batch_labels = tokenizer(yy, return_tensors='pt', spaces=0, padding=True, truncation=True, add_special_tokens=False).to(model.device)\n",
    "\n",
    "    try:\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "        loss = torch.nn.functional.ctc_loss(\n",
    "            logits.transpose(1, 0), \n",
    "            batch_labels.input_ids, \n",
    "            batch.attention_mask.sum(1), \n",
    "            batch_labels.attention_mask.sum(1), \n",
    "            reduction='mean',\n",
    "            zero_infinity=True,\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        if i % gradient_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' not in str(e):\n",
    "            raise e\n",
    "        print(\n",
    "            'error', i, \n",
    "            'sizes:', batch['input_ids'].shape, max(len(_) for _ in xx), \n",
    "            '/', batch_labels['input_ids'].shape, max(len(_) for _ in yy), \n",
    "            e\n",
    "        )\n",
    "        # raise e\n",
    "        loss, logits, batch, batch_labels = None, None, None, None\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        cleanup()\n",
    "        continue\n",
    "\n",
    "    w = 1 / max(1, min(len(losses), window))\n",
    "    ewm_loss = ewm_loss * (1-w) + loss.item() * w\n",
    "    losses.append(loss.item())\n",
    "    tq.set_description(f'{ewm_loss:3.3f}')\n",
    "\n",
    "    if len(losses) % report_steps == 0:\n",
    "        model.eval();\n",
    "        print('step', len(losses), 'loss', np.mean(losses[-report_steps:]), 'error decrease', eval_model())\n",
    "        model.train();\n",
    "        if i > 0:\n",
    "            print('SAVING')\n",
    "            model.save_pretrained(MODEL_NAME)\n",
    "            tokenizer.save_pretrained(MODEL_NAME)\n",
    "    if i % cleanup_steps == 0:\n",
    "        cleanup()\n",
    "    # implement a very late learning rate cooldown\n",
    "    if i >= 460_000:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-4 * (600_000 - i) / (600_000 - 460_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f4d3cc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# step 149000 loss 0.14386079168878496 error decrease 0.3875968992248062\n",
    "# At 460000 steps I accidentially broke the model, by using a x10 larger learning rate than I should have.\n",
    "pd.Series(losses).ewm(3000).mean()[10_000:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c50167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(xx, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144281ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_index_global_attn = batch.attention_mask > 0\n",
    "is_global_attn = is_index_global_attn.flatten().any().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_global_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d02ac070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85e50f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21090464780542a3970acd4b037b2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_small['fixed'] = [fix_text(text, 1) for text in tqdm(dev_small.trash2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af5af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "69987454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance               1.2900\n",
       "normalized_distance    0.0175\n",
       "edit_max_cldiff        0.4600\n",
       "edit_max_lendiff       0.0300\n",
       "change_amount          0.8800\n",
       "new_diff               0.6300\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b0cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5116279069767442"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ba0fb",
   "metadata": {},
   "source": [
    "In the end, the gains seem to be not as good as with a normal BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a3358d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49612403100775193\n",
      "0.49612403100775193\n",
      "0.5116279069767442\n"
     ]
    }
   ],
   "source": [
    "for s in range(3):\n",
    "    print(eval_model(spaces=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "187dd527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ә-ә, уларҙа тормош икенсе, тәр\\xadбиә башҡа төрлө, тиһеңме?'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "761bcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(text, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True).to(model.device)\n",
    "with torch.no_grad():\n",
    "    logits = torch.log_softmax(model(**batch).logits, axis=-1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e248d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 115, 395])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f23808",
   "metadata": {},
   "source": [
    "This beam decoder works, but it is slow as fuck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97c96204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "def decode_ctc_beam(log_proba, num_beams=10, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(0))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    for step in trange(log_proba.shape[0]):\n",
    "        hyp2logscores = defaultdict(list)\n",
    "        for token_id in range(log_proba.shape[1]):\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score + log_proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    hyp2logscores[(seq, False)].append(new_score)\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        hyp2logscores[(seq, True)].append(new_score)\n",
    "                    else:\n",
    "                        hyp2logscores[(seq + (token_id,), True)].append(new_score)\n",
    "        scorer = Counter()\n",
    "        for k, scores in hyp2logscores.items():\n",
    "            scorer[k] = torch.logsumexp(torch.stack(scores), 0)\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return beams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737e079",
   "metadata": {},
   "source": [
    "Speed up by moving into the probabilities space: better, but still fuking slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "01af3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_beam(log_proba, num_beams=10, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(1))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    proba = torch.softmax(log_proba, -1)\n",
    "    for step in trange(log_proba.shape[0]):\n",
    "        scorer = Counter()\n",
    "        for token_id in range(log_proba.shape[1]):\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score * proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    scorer[(seq, False)] += new_score\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        scorer[(seq, True)] += new_score\n",
    "                    else:\n",
    "                        scorer[(seq + (token_id,), True)] += new_score\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f828b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_beam(log_proba, num_beams=10, n2=11, blank_id=0):\n",
    "    \"\"\"Compute the approximate top k hypoheses of CTC and their probabilities\"\"\"\n",
    "    beams = [((), True, torch.tensor(1))]  # triplets of (prefix, is_open, sum_log_probs)\n",
    "    proba = torch.softmax(log_proba, -1)\n",
    "    for step in range(log_proba.shape[0]):\n",
    "        scorer = Counter()\n",
    "        _, indices = torch.topk(proba[step], n2)\n",
    "        for token_id in indices.cpu().numpy():\n",
    "            for (seq, is_open, score) in beams:\n",
    "                new_score = score * proba[step, token_id]\n",
    "                if token_id == blank_id:  # just add blank to the current sequence\n",
    "                    scorer[(seq, False)] += new_score\n",
    "                else:\n",
    "                    if is_open and len(seq) > 0 and token_id == seq[-1]:  # continue the curent open sequence\n",
    "                        scorer[(seq, True)] += new_score\n",
    "                    else:\n",
    "                        scorer[(seq + (token_id,), True)] += new_score\n",
    "        beams = [(seq, is_open, score) for (seq, is_open), score in scorer.most_common(num_beams)]\n",
    "    return [(seq, score.item()) for (seq, is_open, score) in beams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b9d780b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832899808883667 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, тиһеңме?\n",
      "0.035917624831199646 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, - тиһеңме?\n",
      "0.007658788003027439 Ә ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, тиһеңме?\n",
      "0.005061058793216944 Ә-ә, улар ҙа тормош икенсе, тәр­биә башҡа төрлө, тиһеңме?\n",
      "0.003933039028197527 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө тиһеңме?\n"
     ]
    }
   ],
   "source": [
    "beams = decode_ctc_beam(logits[0], n2=20)\n",
    "for hyp, score in beams[:5]:\n",
    "    print(score, ''.join(tokenizer.convert_ids_to_tokens(hyp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "363fbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8234241008758545 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, тиһеңме?\n",
      "0.03550899028778076 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, - тиһеңме?\n",
      "0.0038908934220671654 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө тиһеңме?\n",
      "0.0016263878205791116 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, тиһеңме.\n",
      "0.001475932658649981 Ә-ә, уларҙа тормош икенсе, тәр­биә башҡа төрлө, тиhеңме?\n"
     ]
    }
   ],
   "source": [
    "beams = decode_ctc_beam(logits[0], num_beams=5, n2=5)\n",
    "for hyp, score in beams[:5]:\n",
    "    print(score, ''.join(tokenizer.convert_ids_to_tokens(hyp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c113218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_text_beam(text, verbose=False, spaces=1, num_beams=5, num_top=5):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True, return_token_type_ids=False).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    if num_beams <= 1:\n",
    "        return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)\n",
    "    hyps = decode_ctc_beam(logits[0], num_beams=num_beams, n2=num_top)\n",
    "    return tokenizer.decode(hyps[0][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cc643973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19405475f4e4cdf9314c2d5cbe31e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_small['fixed'] = [fix_text_beam(text, spaces=1, num_beams=5, num_top=3) for text in tqdm(dev_small.trash2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4c846455",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69987454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance               1.2900\n",
       "normalized_distance    0.0175\n",
       "edit_max_cldiff        0.4600\n",
       "edit_max_lendiff       0.0300\n",
       "change_amount          1.6600\n",
       "new_diff               1.3500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8b0cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04651162790697683"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "97c480d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19699                                                                                                                                                  Делагоа ҡултығында.\n",
       "965                                                            Диуарҙар буйлап бер өҫкә, бер аҫҡа күсеп, иң өҫкө ҡатарҙағы өй эстәрен, залдарҙы, сарҙаҡтарҙы ҡарап сыҡтым.\n",
       "13577                                                                                                            Үҙ-ара сәңгелдәшеп: - Йөрөй шунда, ҡартайғанда тыртайған!\n",
       "12487                                                                                                                                            Ҡорбанғәле, һиңә әйтәмсе.\n",
       "20720                                                                     Ошо һүҙән һуң уның тауышы өҙөлдө, һәм ул, нисек торһа - шул килеш, бөтә аяҡтары менән ергә ауҙы.\n",
       "                                                                                       ...                                                                                \n",
       "23813                                                                          Казаға тарыҡан ошо каруанға юл белеүсе бер юламан тап булып, уны һыу янына алып килгән, ти.\n",
       "8808     Кешеһеҙ тып-тын юлда шулай моң сәсеп барыуының, үҙ һыуһынын ғына ҡандырып ҡалмайынса, атаһына ла әлә ни хәтлем илаһи бер рәхәтлек биреүен беләме икән Төлкөсура?.\n",
       "5764                                                                                                      Диңгеҙе көндөҙ үк аҡ күбекә манған ел тағы ла көсәйә ине шикеле.\n",
       "1923                                                                                                 Теге кеше шәпшәп атлап ары китеп бара; эргә-тирәлә башҡа берәү ҙә юҡ.\n",
       "5144                                                               Улар ағаһы, еңгәһе, уларҙың бер йәшлек кенә улдары Салауат дүртәүләп, Сәлимә мәрхүмдең өйөндә йәшәйҙәр.\n",
       "Name: fixed, Length: 100, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small['fixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a39b1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aacf463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean2</th>\n",
       "      <th>fixed</th>\n",
       "      <th>new_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>Улар башлыса Урал аръяғында күбәйә барған иген игеүсе ауылдарҙан йыйылғайны. ...Төлкөсура үҙенә йылғаны ҡайҙан кисеү кәрәклеген күрһәткән билдәләрҙе алыҫтан уҡ абайлап килде.</td>\n",
       "      <td>Улар башлыса Урал аръяғында күбәйә барған иген итеүсе ауылдарҙан йыйылғайны. .Төлкөсура үҙенә йылғаны ҡайҙан кисеү кәрәклеген күрһәткән билдәләрҙе алыҫтан уҡ абайлап килде.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>Ҡазаға тарыҡҡан ошо каруанға юл белеүсе бер юламан тап булып, уны һыу янына алып килгән, ти.</td>\n",
       "      <td>Казаға тарыҡан ошо каруанға юл белеүсе бер юламан тап булып, уны һыу янына алып килгән, ти.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15509</th>\n",
       "      <td>Быуа йылғаның һай ғына ситендә - ҡырсынлыҡта ине.</td>\n",
       "      <td>Быуа йылғаның һай ғына ситендә ҡырсынлыҡта ине.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                               clean2  \\\n",
       "15073  Улар башлыса Урал аръяғында күбәйә барған иген игеүсе ауылдарҙан йыйылғайны. ...Төлкөсура үҙенә йылғаны ҡайҙан кисеү кәрәклеген күрһәткән билдәләрҙе алыҫтан уҡ абайлап килде.   \n",
       "23813                                                                                    Ҡазаға тарыҡҡан ошо каруанға юл белеүсе бер юламан тап булып, уны һыу янына алып килгән, ти.   \n",
       "15509                                                                                                                               Быуа йылғаның һай ғына ситендә - ҡырсынлыҡта ине.   \n",
       "\n",
       "                                                                                                                                                                              fixed  \\\n",
       "15073  Улар башлыса Урал аръяғында күбәйә барған иген итеүсе ауылдарҙан йыйылғайны. .Төлкөсура үҙенә йылғаны ҡайҙан кисеү кәрәклеген күрһәткән билдәләрҙе алыҫтан уҡ абайлап килде.   \n",
       "23813                                                                                   Казаға тарыҡан ошо каруанға юл белеүсе бер юламан тап булып, уны һыу янына алып килгән, ти.   \n",
       "15509                                                                                                                               Быуа йылғаның һай ғына ситендә ҡырсынлыҡта ине.   \n",
       "\n",
       "       new_diff  \n",
       "15073         3  \n",
       "23813         2  \n",
       "15509         2  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small[['clean2', 'fixed', 'new_diff']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7e96d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Уны алып барып ҡушҡан кешеләр төркөмөндә Герард-туған да бар ине, ул инде барыһын һорашып-белеп өлгөргәйне.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5ac38dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=1, num_top=1) == fix_text(text, spaces=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8cc50dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Уны алып барып ҡушҡан кешеләр төркөмөндә Герард-туған да бар ине, ул инде барыһын һорашып-белеп өлгөргәйне.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=1, num_top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6a5cbc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Уны алып барып ҡушҡан кешеләр төркөмөндә Герард-туған да бар ине, ул инде барыһын һорашып-белеп өлгөргәйне.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_text_beam(text, spaces=1, num_beams=5, num_top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f029ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
