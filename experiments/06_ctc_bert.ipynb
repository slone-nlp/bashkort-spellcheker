{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f75b144",
   "metadata": {},
   "source": [
    "The idea is the same as in the notebooks 3 and 5, \"seq labeling\", but now we use a simple 1-gram vocabulary, and to compensate for this, we upsample the input characters and use CTC loss to compensate for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f6e47",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fc96a",
   "metadata": {},
   "source": [
    "## 1. 1. Load the parallel text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd1cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3133)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(torch.stack([torch.tensor(1), torch.tensor(2)]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaffe14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trash</th>\n",
       "      <th>clean</th>\n",
       "      <th>trash2</th>\n",
       "      <th>clean2</th>\n",
       "      <th>distance</th>\n",
       "      <th>normalized_distance</th>\n",
       "      <th>split</th>\n",
       "      <th>edit_max_cldiff</th>\n",
       "      <th>edit_max_lendiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>«Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Минең генә бер кешем дә юҡ, тип шунда уҡ танау...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, тип шунда уҡ танау...</td>\n",
       "      <td>Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23886</th>\n",
       "      <td>Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23887</th>\n",
       "      <td>Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...</td>\n",
       "      <td>Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23890</th>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...</td>\n",
       "      <td>Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   trash  \\\n",
       "0      Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, тип шунда уҡ танау...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...   \n",
       "23888  Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...   \n",
       "\n",
       "                                                   clean  \\\n",
       "0      Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...   \n",
       "23888  Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...   \n",
       "\n",
       "                                                  trash2  \\\n",
       "0      Шунда ук әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...   \n",
       "1            Унан беҙ өсөбөҙ ҙә ултырғыстарға ултырабыҙ.   \n",
       "2      «Иҫән-Һау ғына тороғоҙ инде», - тип бышылдай у...   \n",
       "3      Минең генә бер кешем дә юҡ, тип шунда уҡ танау...   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...   \n",
       "...                                                  ...   \n",
       "23886  Эҫтәрендә бүре үк оломаһа ла, эттәр шыңшый баш...   \n",
       "23887  Үткән йәйҙә яман томра көндө Кәҙерғол төбәгенд...   \n",
       "23888  Кайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...   \n",
       "23889  Кыш урталарында бер көн Әбдрәшит ат аҙбарынан ...   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар ҡупшы ғына ите...   \n",
       "\n",
       "                                                  clean2  distance  \\\n",
       "0      Шунда уҡ әсәйемдең тоҡсайын, төйөнсөктәрен күҙ...         1   \n",
       "1            Унан беҙ әсәбеҙ ҙә ултырғыстарға ултырабыҙ.         3   \n",
       "2      «Иҫән-һау ғына тороғоҙ инде», - тип бышылдай у...         1   \n",
       "3      Минең генә бер кешем дә юҡ, - тип шунда уҡ тан...         2   \n",
       "4      Ай йөрөгән, ти, йыл йөрөгән, ти, батыр, ете та...         1   \n",
       "...                                                  ...       ...   \n",
       "23886  Эстәрендә бүре үк оломаһа ла, эттәр шыңшый баш...         1   \n",
       "23887  Үткән йәйҙә яман томра көндө Ҡәҙерғол төбәгенд...         1   \n",
       "23888  Ҡайтыр алдынан салбарҙы эҙләй башлаһа, таба ал...         1   \n",
       "23889  Ҡыш урталарында бер көн Әбдрәшит ат аҙбарынан ...         1   \n",
       "23890  Шатлыҡ тигәнебеҙ юғалған салбар - ҡупшы ғына и...         2   \n",
       "\n",
       "       normalized_distance  split  edit_max_cldiff  edit_max_lendiff  \n",
       "0                 0.015385  train                1                 0  \n",
       "1                 0.069767   test                1                 0  \n",
       "2                 0.014085    dev                1                 0  \n",
       "3                 0.029412  train                0                 0  \n",
       "4                 0.012500  train                1                 0  \n",
       "...                    ...    ...              ...               ...  \n",
       "23886             0.020000    dev                1                 0  \n",
       "23887             0.009524  train                1                 0  \n",
       "23888             0.020000  train                1                 0  \n",
       "23889             0.009174  train                1                 0  \n",
       "23890             0.021053  train                0                 0  \n",
       "\n",
       "[23891 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv('../data/spellchecker_dataset_split.tsv', sep='\\t')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b03813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14382, 9)\n",
      "(14171, 9)\n",
      "(14085, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_train = df_orig[(df_orig.split=='train')]\n",
    "print(df_orig_train.shape)\n",
    "\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_cldiff <= 3]\n",
    "print(df_orig_train.shape)\n",
    "df_orig_train = df_orig_train[df_orig_train.edit_max_lendiff <= 1].copy()\n",
    "print(df_orig_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5f5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4611, 9)\n"
     ]
    }
   ],
   "source": [
    "df_orig_dev = df_orig[(df_orig.split=='dev') & (df_orig.edit_max_cldiff <= 3) & (df_orig.edit_max_lendiff <= 1)]\n",
    "print(df_orig_dev.shape)\n",
    "dev_small = df_orig_dev.sample(100, random_state=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154994",
   "metadata": {},
   "source": [
    "## 1.2. Corrupt the clean sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "851b9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605495\n"
     ]
    }
   ],
   "source": [
    "with open('../data/clean_bk_sents.txt', 'r') as f:\n",
    "    cs2 = [line.strip() for line in f]\n",
    "print(len(cs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ba88fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~¢¦§ª«¬­®°²µ·»¿ÀÁÂÄÉÊÌÍÎÐÒÖ×ØÜÝÞàáâãäåçèéêëìíîïðñòóôõö÷øûüýÿāČčğıłŠšūŽžƏəɵʺ̶́ΒΠΧЁЃЄЅІЉЋЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёђѓєѕіїљњћќўџѲѳҐҒғҖҗҘҙқҠҡҢңҪҫҮүҰҺһӊӘәӧӨөاتخرسعكنو​‎‐‑‒–—―‘’“”„•…‰›⁠№Ⅰ→∂−≥⏰─●☎⚡✒✓✨﻿🌸🎭📝\n",
      "349\n",
      " !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~¢¦§ª«¬­®°²µ·»¿ÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖ×ØÛÜÝÞàáâãäåçèéêëìíîïðñòóôõö÷øûüýþÿĀāČčĞğıŁłŠšŪūŸŽžƏƟəɵʺ̶́ΒΜΠΧβπχЁЂЃЄЅІЇЉЊЋЌЎЏАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёђѓєѕіїљњћќўџѲѳҐґҒғҖҗҘҙҚқҠҡҢңҪҫҮүҰұҺһӉӊӘәӦӧӨөاتخرسعكنو​‎‐‑‒–—―‘’“”„•…‰›⁠№Ⅰⅰ→∂−≥⏰─●☎⚡✒✓✨﻿🌸🎭📝\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "all_chars = ''.join(sorted({\n",
    "    c for texts in [cs2, df_orig_train.trash, df_orig_train.clean] \n",
    "    for text in texts for c in text\n",
    "}))\n",
    "print(all_chars)\n",
    "print(len(all_chars))\n",
    "\n",
    "all_chars = ''.join(sorted(set(all_chars + all_chars.upper() + all_chars.lower())))\n",
    "print(all_chars)\n",
    "print(len(all_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3120603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisers import add_simple_noise\n",
    "from noisers import Noiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e058f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiser = Noiser.load('noise_model_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbd24e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Тәңре уға тәғәйен иткән юлды һәр кем үҙе генә үтә һәм маңлайына яҙылған эш-ғәмәлдәрҙе фәҡәт үҙ ҡулы менән атҡара.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = random.choice(cs2)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "797922d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Тәңре уға тәғәйен иткән юлды һәр кем үҙе генә үт¦ә һәм маңлайына яҙылған%эш-ғәмәлдәрҙе фәҡәт☎ ћҙ ҡулы менән атҡара.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_simple_noise(text, all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c924939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Тәңре уға тәғәйен иткән юлды һәр кем үҙе генә үтә һәм маң*лайына яҙьшған эш-ғәмәлдәрҙе фәҡәт үҙ ҡулы менән атҡарә.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noiser.add_noise(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b019f",
   "metadata": {},
   "source": [
    "# 2. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f9e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "VOCAB = ['▁', '[pad]', '[unk]', '[cls]', '[sep]', '[mask]', '[bos]', '[eos]'] + list(all_chars)\n",
    "print(len(VOCAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e8fb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_vocab.txt', 'w') as f:\n",
    "    for t in VOCAB:\n",
    "        print(t, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312b8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import char_tokenizer\n",
    "from importlib import reload\n",
    "reload(char_tokenizer)\n",
    "from char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba8b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(vocab_file='char_vocab.txt', model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5920d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec812df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = BertConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=512,\n",
    "    max_position_embeddings=tokenizer.model_max_length,\n",
    "    type_vocab_size=1,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    position_embedding_type='relative_key_query',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ecf2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e6fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '../models/bert-char-ctc-bak-denoise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665ef2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/bert-char-ctc-bak-denoise\\\\tokenizer_config.json',\n",
       " '../models/bert-char-ctc-bak-denoise\\\\special_tokens_map.json',\n",
       " '../models/bert-char-ctc-bak-denoise\\\\vocab.txt',\n",
       " '../models/bert-char-ctc-bak-denoise\\\\added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b66c54",
   "metadata": {},
   "source": [
    "# 3. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6468b660",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19100/3970710264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88c0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "\n",
    "def fix_text(text, verbose=False, spaces=2):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89ca814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(spaces=2):\n",
    "    dev_small['fixed'] = [fix_text(text, spaces=spaces) for text in dev_small.trash2]\n",
    "    dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "    dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)\n",
    "    return 1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "200079dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015503875968992276"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "564e87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-2,\n",
    ")\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "149211e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4048e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_loss = 0\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0df75dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "share_real = 0.1\n",
    "share_noiser = 0.4\n",
    "p_keep = 0.2\n",
    "\n",
    "report_steps = 1000  # раз в сколько шагов печатаем результат\n",
    "cleanup_steps = 100  # раз в сколько батчей чистим память\n",
    "\n",
    "gradient_steps = 1  # раз в сколько батчей обновляем параметры \n",
    "window = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa9f3b",
   "metadata": {},
   "source": [
    "Wow, this is the speed I like! 5 iterations per second, with 64 samples per batch, on my laptop GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2521750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345b44731cf04aa3825d8f217ea77438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/297826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000 loss 0.3351442826408893 error decrease -0.007751937984496138\n",
      "SAVING\n",
      "step 4000 loss 0.36188816670142115 error decrease 0.023255813953488413\n",
      "SAVING\n",
      "step 5000 loss 0.30822691893391313 error decrease 0.03100775193798455\n",
      "SAVING\n",
      "step 6000 loss 0.3383087878935039 error decrease 0.007751937984496138\n",
      "SAVING\n",
      "step 7000 loss 0.3273058985415846 error decrease 0.015503875968992276\n",
      "SAVING\n",
      "step 8000 loss 0.3242420162037015 error decrease 0.007751937984496138\n",
      "SAVING\n",
      "step 9000 loss 0.31116471908800303 error decrease 0.0\n",
      "SAVING\n",
      "step 10000 loss 0.33094022853299976 error decrease 0.023255813953488413\n",
      "SAVING\n",
      "step 11000 loss 0.3342750302515924 error decrease -0.09302325581395343\n",
      "SAVING\n",
      "step 12000 loss 0.2979228977262974 error decrease 0.046511627906976716\n",
      "SAVING\n",
      "step 13000 loss 0.29272264916449786 error decrease 0.054263565891472854\n",
      "SAVING\n",
      "step 14000 loss 0.26522703042626383 error decrease 0.07751937984496127\n",
      "SAVING\n",
      "step 15000 loss 0.2960522537855431 error decrease 0.015503875968992276\n",
      "SAVING\n",
      "step 16000 loss 0.28923457203805447 error decrease 0.10852713178294571\n",
      "SAVING\n",
      "step 17000 loss 0.28361121108941734 error decrease 0.13178294573643412\n",
      "SAVING\n",
      "step 18000 loss 0.26154544287733733 error decrease 0.06201550387596899\n",
      "SAVING\n",
      "step 19000 loss 0.2521282569374889 error decrease 0.07751937984496127\n",
      "SAVING\n",
      "step 20000 loss 0.24659172529447823 error decrease 0.07751937984496127\n",
      "SAVING\n",
      "step 21000 loss 0.23370905189123004 error decrease 0.1472868217054264\n",
      "SAVING\n",
      "step 22000 loss 0.2372128542056307 error decrease 0.10077519379844957\n",
      "SAVING\n",
      "step 23000 loss 0.23597894884459675 error decrease 0.18604651162790697\n",
      "SAVING\n",
      "step 24000 loss 0.24965124481450765 error decrease 0.12403100775193798\n",
      "SAVING\n",
      "step 25000 loss 0.2255691984836012 error decrease 0.2093023255813954\n",
      "SAVING\n",
      "step 26000 loss 0.22367604825645684 error decrease 0.11627906976744184\n",
      "SAVING\n",
      "step 27000 loss 0.22069776795059443 error decrease 0.12403100775193798\n",
      "SAVING\n",
      "step 28000 loss 0.21030127509776503 error decrease 0.20155038759689925\n",
      "SAVING\n",
      "step 29000 loss 0.21256800766475498 error decrease 0.12403100775193798\n",
      "SAVING\n",
      "step 30000 loss 0.23364503728970884 error decrease 0.17829457364341084\n",
      "SAVING\n",
      "step 31000 loss 0.2233124426882714 error decrease 0.18604651162790697\n",
      "SAVING\n",
      "step 32000 loss 0.20678993527032435 error decrease 0.18604651162790697\n",
      "SAVING\n",
      "step 33000 loss 0.21043161340756342 error decrease 0.1937984496124031\n",
      "SAVING\n",
      "step 34000 loss 0.19682428178843112 error decrease 0.18604651162790697\n",
      "SAVING\n",
      "step 35000 loss 0.21015058295149355 error decrease 0.2558139534883721\n",
      "SAVING\n",
      "step 36000 loss 0.21072139772027731 error decrease 0.17829457364341084\n",
      "SAVING\n",
      "step 37000 loss 0.1972805921458639 error decrease 0.1705426356589147\n",
      "SAVING\n",
      "step 38000 loss 0.2035249921535142 error decrease 0.24031007751937983\n",
      "SAVING\n",
      "step 39000 loss 0.2157170383548364 error decrease 0.22480620155038755\n",
      "SAVING\n",
      "step 40000 loss 0.193581256352365 error decrease 0.2325581395348837\n",
      "SAVING\n",
      "step 41000 loss 0.1948195855161175 error decrease 0.24031007751937983\n",
      "SAVING\n",
      "step 42000 loss 0.19103944379417226 error decrease 0.28682170542635654\n",
      "SAVING\n",
      "step 43000 loss 0.2024326894329861 error decrease 0.2945736434108527\n",
      "SAVING\n",
      "step 44000 loss 0.19150213961303234 error decrease 0.2945736434108527\n",
      "SAVING\n",
      "step 45000 loss 0.20068345909845084 error decrease 0.2093023255813954\n",
      "SAVING\n",
      "step 46000 loss 0.19421802717400716 error decrease 0.2558139534883721\n",
      "SAVING\n",
      "step 47000 loss 0.1959790056697093 error decrease 0.2713178294573644\n",
      "SAVING\n",
      "step 48000 loss 0.1932585818702355 error decrease 0.2093023255813954\n",
      "SAVING\n",
      "step 49000 loss 0.19528759153559805 error decrease 0.2325581395348837\n",
      "SAVING\n",
      "step 50000 loss 0.1993436918691732 error decrease 0.24806201550387597\n",
      "SAVING\n",
      "step 51000 loss 0.16905199096770956 error decrease 0.22480620155038755\n",
      "SAVING\n",
      "step 52000 loss 0.2008725090357475 error decrease 0.2093023255813954\n",
      "SAVING\n",
      "step 53000 loss 0.18598689613165334 error decrease 0.2325581395348837\n",
      "SAVING\n",
      "step 54000 loss 0.18682825500844047 error decrease 0.22480620155038755\n",
      "SAVING\n",
      "step 55000 loss 0.18876721880957484 error decrease 0.2558139534883721\n",
      "SAVING\n",
      "step 56000 loss 0.1747444538855925 error decrease 0.26356589147286824\n",
      "SAVING\n",
      "step 57000 loss 0.2067488106447272 error decrease 0.2790697674418605\n",
      "SAVING\n",
      "step 58000 loss 0.17703966054227202 error decrease 0.34883720930232553\n",
      "SAVING\n",
      "step 59000 loss 0.19372584207402543 error decrease 0.2945736434108527\n",
      "SAVING\n",
      "step 60000 loss 0.18227129087410868 error decrease 0.28682170542635654\n",
      "SAVING\n",
      "step 61000 loss 0.1886859896387905 error decrease 0.28682170542635654\n",
      "SAVING\n",
      "step 62000 loss 0.16377890360169112 error decrease 0.20155038759689925\n",
      "SAVING\n",
      "step 63000 loss 0.17838472773786634 error decrease 0.2558139534883721\n",
      "SAVING\n",
      "step 64000 loss 0.1869132277490571 error decrease 0.3023255813953488\n",
      "SAVING\n",
      "step 65000 loss 0.18575137187261134 error decrease 0.3023255813953488\n",
      "SAVING\n",
      "step 66000 loss 0.1787361011696048 error decrease 0.31007751937984496\n",
      "SAVING\n",
      "step 67000 loss 0.16637803795235231 error decrease 0.3023255813953488\n",
      "SAVING\n",
      "step 68000 loss 0.17757128177722917 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 69000 loss 0.18735105784609915 error decrease 0.2713178294573644\n",
      "SAVING\n",
      "step 70000 loss 0.17389816680317743 error decrease 0.2790697674418605\n",
      "SAVING\n",
      "step 71000 loss 0.17630327181797475 error decrease 0.2790697674418605\n",
      "SAVING\n",
      "step 72000 loss 0.18795750519726426 error decrease 0.24806201550387597\n",
      "SAVING\n",
      "step 73000 loss 0.16430403446685524 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 74000 loss 0.176118082201574 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 75000 loss 0.18907413645042107 error decrease 0.37209302325581395\n",
      "SAVING\n",
      "step 76000 loss 0.1669774494431913 error decrease 0.3178294573643411\n",
      "SAVING\n",
      "step 77000 loss 0.16600389786856248 error decrease 0.2325581395348837\n",
      "SAVING\n",
      "step 78000 loss 0.16114647527690976 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 79000 loss 0.15871225354727359 error decrease 0.31007751937984496\n",
      "SAVING\n",
      "step 80000 loss 0.16725331027479842 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 81000 loss 0.16862295095529406 error decrease 0.2713178294573644\n",
      "SAVING\n",
      "step 82000 loss 0.17269598051253707 error decrease 0.3178294573643411\n",
      "SAVING\n",
      "step 83000 loss 0.16440403441991658 error decrease 0.3178294573643411\n",
      "SAVING\n",
      "step 84000 loss 0.16799120870558545 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 85000 loss 0.1713293222784996 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 86000 loss 0.1605271067833528 error decrease 0.37209302325581395\n",
      "SAVING\n",
      "step 87000 loss 0.15266275637596846 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 88000 loss 0.15771881486987696 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 89000 loss 0.1547056532651186 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 90000 loss 0.16265069145988673 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 91000 loss 0.15324589159851892 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 92000 loss 0.16234960213163868 error decrease 0.3643410852713178\n",
      "SAVING\n",
      "step 93000 loss 0.1676527882940136 error decrease 0.24031007751937983\n",
      "SAVING\n",
      "step 94000 loss 0.17148906918149442 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 95000 loss 0.16048617157246917 error decrease 0.34883720930232553\n",
      "SAVING\n",
      "step 96000 loss 0.1519703347031027 error decrease 0.3643410852713178\n",
      "SAVING\n",
      "step 97000 loss 0.15815560177201404 error decrease 0.3178294573643411\n",
      "SAVING\n",
      "step 98000 loss 0.1599231301038526 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 99000 loss 0.1596383239054121 error decrease 0.3798449612403101\n",
      "SAVING\n",
      "step 100000 loss 0.15047419275715948 error decrease 0.3643410852713178\n",
      "SAVING\n",
      "step 101000 loss 0.1661363378185779 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 102000 loss 0.1765411010265816 error decrease 0.2713178294573644\n",
      "SAVING\n",
      "step 103000 loss 0.15753856655675919 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 104000 loss 0.15300512722926216 error decrease 0.3798449612403101\n",
      "SAVING\n",
      "step 105000 loss 0.1602060755849816 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 106000 loss 0.15033475113241002 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 107000 loss 0.15145907857827842 error decrease 0.3798449612403101\n",
      "SAVING\n",
      "step 108000 loss 0.1463403846938163 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 109000 loss 0.16379147320007906 error decrease 0.3643410852713178\n",
      "SAVING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 110000 loss 0.146723149424186 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 111000 loss 0.15154756888188423 error decrease 0.3798449612403101\n",
      "SAVING\n",
      "step 112000 loss 0.160171855897177 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 113000 loss 0.14404648092249409 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 114000 loss 0.1458556364630349 error decrease 0.37209302325581395\n",
      "SAVING\n",
      "step 115000 loss 0.14236843575211242 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 116000 loss 0.14362568270601334 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 117000 loss 0.14816099842824043 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 118000 loss 0.13235429579624905 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 119000 loss 0.151375465081539 error decrease 0.2945736434108527\n",
      "SAVING\n",
      "step 120000 loss 0.14319267445942388 error decrease 0.31007751937984496\n",
      "SAVING\n",
      "step 121000 loss 0.13956063600396737 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 122000 loss 0.14835485884686933 error decrease 0.33333333333333337\n",
      "SAVING\n",
      "step 123000 loss 0.14846881605964155 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 124000 loss 0.13773855683906003 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 125000 loss 0.15415163004631177 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 126000 loss 0.15086308135744184 error decrease 0.34883720930232553\n",
      "SAVING\n",
      "step 127000 loss 0.1422188194692135 error decrease 0.37209302325581395\n",
      "SAVING\n",
      "step 128000 loss 0.15246342713292688 error decrease 0.34883720930232553\n",
      "SAVING\n",
      "step 129000 loss 0.16301859560771845 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 130000 loss 0.13608989008073696 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 131000 loss 0.14436867331736722 error decrease 0.48062015503875966\n",
      "SAVING\n",
      "step 132000 loss 0.14370897744037212 error decrease 0.41860465116279066\n",
      "SAVING\n",
      "step 133000 loss 0.15086746772937476 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "step 134000 loss 0.1467698758277111 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 135000 loss 0.14353087830729783 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 136000 loss 0.14303683763602748 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 137000 loss 0.13372993393940852 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 138000 loss 0.1438394331410527 error decrease 0.4496124031007752\n",
      "SAVING\n",
      "step 139000 loss 0.13856136918859557 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 140000 loss 0.14201455404353328 error decrease 0.41860465116279066\n",
      "SAVING\n",
      "step 141000 loss 0.14784343785978854 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "step 142000 loss 0.13662549755955114 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 143000 loss 0.1333445378106553 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 144000 loss 0.12943188540963457 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 145000 loss 0.13388804554985836 error decrease 0.4496124031007752\n",
      "SAVING\n",
      "step 146000 loss 0.13918391093029642 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 147000 loss 0.12791403290908784 error decrease 0.45736434108527135\n",
      "SAVING\n",
      "step 148000 loss 0.14193510707514362 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 149000 loss 0.1438702181871049 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 150000 loss 0.1270374352389481 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 151000 loss 0.1468961242379155 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 152000 loss 0.12958055625041015 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 153000 loss 0.12516544337291272 error decrease 0.4496124031007752\n",
      "SAVING\n",
      "step 154000 loss 0.13345612629875542 error decrease 0.3798449612403101\n",
      "SAVING\n",
      "step 155000 loss 0.13250996283162386 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "step 156000 loss 0.14921401056135072 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "step 157000 loss 0.14361352984490805 error decrease 0.3565891472868217\n",
      "SAVING\n",
      "step 158000 loss 0.13273714271280915 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 159000 loss 0.13587653599656188 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 160000 loss 0.12976280683418737 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 161000 loss 0.13848357911081985 error decrease 0.3410852713178295\n",
      "SAVING\n",
      "step 162000 loss 0.1311565064380411 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 163000 loss 0.13945922799734398 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 164000 loss 0.13004075659113004 error decrease 0.4496124031007752\n",
      "SAVING\n",
      "step 165000 loss 0.1398297494442668 error decrease 0.37209302325581395\n",
      "SAVING\n",
      "step 166000 loss 0.12277810859354213 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 167000 loss 0.13066051722574049 error decrease 0.3875968992248062\n",
      "SAVING\n",
      "step 168000 loss 0.1290288997690659 error decrease 0.4108527131782945\n",
      "SAVING\n",
      "step 169000 loss 0.12768960253195838 error decrease 0.41860465116279066\n",
      "SAVING\n",
      "step 170000 loss 0.13759558032499628 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 171000 loss 0.1299808360247407 error decrease 0.4651162790697675\n",
      "SAVING\n",
      "step 172000 loss 0.12610333370720037 error decrease 0.4418604651162791\n",
      "SAVING\n",
      "step 173000 loss 0.1301465878880117 error decrease 0.45736434108527135\n",
      "SAVING\n",
      "step 174000 loss 0.12256307028629818 error decrease 0.4263565891472868\n",
      "SAVING\n",
      "step 175000 loss 0.13150122391455807 error decrease 0.43410852713178294\n",
      "SAVING\n",
      "step 176000 loss 0.14081828967598267 error decrease 0.4651162790697675\n",
      "SAVING\n",
      "step 177000 loss 0.1258960251137614 error decrease 0.4031007751937985\n",
      "SAVING\n",
      "step 178000 loss 0.1334425189588219 error decrease 0.39534883720930236\n",
      "SAVING\n",
      "step 179000 loss 0.13897017484111712 error decrease 0.4651162790697675\n",
      "SAVING\n",
      "step 180000 loss 0.1388684742685873 error decrease 0.4108527131782945\n",
      "SAVING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/3365949506.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         loss = torch.nn.functional.ctc_loss(\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mbatch_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mctc_loss\u001b[1;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[0;32m   2626\u001b[0m             \u001b[0mblank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_infinity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzero_infinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2627\u001b[0m         )\n\u001b[1;32m-> 2628\u001b[1;33m     return torch.ctc_loss(\n\u001b[0m\u001b[0;32m   2629\u001b[0m         \u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_infinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "cleanup()\n",
    "model.train()\n",
    "\n",
    "tq = trange(len(losses), 300_000)\n",
    "for i in tq:\n",
    "    r = random.random()\n",
    "    if r < share_real:\n",
    "        batch = df_orig_train.sample(batch_size)\n",
    "        xx, yy = batch.trash2.tolist(), batch.clean2.tolist()\n",
    "    elif r < share_real + share_noiser:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [noiser.add_noise(text, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    else:\n",
    "        yy = random.sample(cs2, batch_size)\n",
    "        xx = [add_simple_noise(text, all_chars, edit_rate=0.05) if random.random() > p_keep else text for text in yy]\n",
    "    \n",
    "    random_spaces = random.choices([0, 1, 2], weights=[0.1, 0.7, 0.2])[0]\n",
    "    batch = tokenizer(xx, return_tensors='pt', spaces=random_spaces, padding=True, truncation=True).to(model.device)\n",
    "    batch_labels = tokenizer(yy, return_tensors='pt', spaces=0, padding=True, truncation=True, add_special_tokens=False).to(model.device)\n",
    "\n",
    "    try:\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "        loss = torch.nn.functional.ctc_loss(\n",
    "            logits.transpose(1, 0), \n",
    "            batch_labels.input_ids, \n",
    "            batch.attention_mask.sum(1), \n",
    "            batch_labels.attention_mask.sum(1), \n",
    "            reduction='mean',\n",
    "            zero_infinity=True,\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        if i % gradient_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "    except RuntimeError as e:\n",
    "        print(\n",
    "            'error', i, \n",
    "            'sizes:', batch['input_ids'].shape, max(len(_) for _ in xx), \n",
    "            '/', batch_labels['input_ids'].shape, max(len(_) for _ in yy), \n",
    "            e\n",
    "        )\n",
    "        # raise e\n",
    "        loss, logits, batch, batch_labels = None, None, None, None\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        cleanup()\n",
    "        continue\n",
    "\n",
    "    w = 1 / max(1, min(len(losses), window))\n",
    "    ewm_loss = ewm_loss * (1-w) + loss.item() * w\n",
    "    losses.append(loss.item())\n",
    "    tq.set_description(f'{ewm_loss:3.3f}')\n",
    "\n",
    "    if len(losses) % report_steps == 0:\n",
    "        model.eval();\n",
    "        print('step', len(losses), 'loss', np.mean(losses[-report_steps:]), 'error decrease', eval_model())\n",
    "        model.train();\n",
    "        if i > 0:\n",
    "            print('SAVING')\n",
    "            model.save_pretrained(MODEL_NAME)\n",
    "            tokenizer.save_pretrained(MODEL_NAME)\n",
    "    if i % cleanup_steps == 0:\n",
    "        cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c26a899a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/3448842004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/188570627.py\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\cuda\\memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m     \"\"\"\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "loss, logits, batch, batch_labels = None, None, None, None\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ae9cd55",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/3562934567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfix_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/1975180729.py\u001b[0m in \u001b[0;36mfix_text\u001b[1;34m(text, verbose, spaces)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfix_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;31m# into a HalfTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;31m# into a HalfTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "fix_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d02ac070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85e50f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c33b1bfee744868a76be1381cccb9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_small['fixed'] = [fix_text(text) for text in tqdm(dev_small.trash2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af5af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69987454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance               1.2900\n",
       "normalized_distance    0.0175\n",
       "edit_max_cldiff        0.4600\n",
       "edit_max_lendiff       0.0300\n",
       "change_amount          0.0900\n",
       "new_diff               1.2700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_small.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b0cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015503875968992276"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3358d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/1884720784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/737069797.py\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(spaces)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fixed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfix_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrash2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'change_amount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtextdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrash2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_diff'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtextdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_diff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/737069797.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fixed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfix_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrash2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'change_amount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtextdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrash2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdev_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_diff'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtextdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_diff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdev_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/1975180729.py\u001b[0m in \u001b[0;36mfix_text\u001b[1;34m(text, verbose, spaces)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfix_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;31m# into a HalfTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;31m# into a HalfTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for s in range(3):\n",
    "    print(eval_model(spaces=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187dd527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 5, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, 2) + (3, 5, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f38ea",
   "metadata": {},
   "source": [
    "# Reproduce the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f391747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf01991",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '../models/bert-char-ctc-bak-denoise'\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME).cuda()\n",
    "tokenizer = CharTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a47037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_text(text, verbose=False, spaces=2):\n",
    "    with torch.inference_mode():\n",
    "        batch = tokenizer(text, return_tensors='pt', spaces=spaces, padding=True, truncation=True, return_token_type_ids=False).to(model.device)\n",
    "        logits = torch.log_softmax(model(**batch).logits, axis=-1)\n",
    "    return tokenizer.decode(logits[0].argmax(-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6e81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf612c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(spaces=1):\n",
    "    dev_small['fixed'] = [fix_text(text, spaces=spaces) for text in dev_small.trash2]\n",
    "    dev_small['change_amount'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.trash2, row.fixed), axis=1)\n",
    "    dev_small['new_diff'] = dev_small.apply(lambda row: textdistance.levenshtein.distance(row.clean2, row.fixed), axis=1)\n",
    "    return 1 - dev_small.new_diff.sum() / dev_small.distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad2d3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9147286821705427\n",
      "0.4108527131782945\n",
      "0.4108527131782945\n",
      "0.26356589147286824\n"
     ]
    }
   ],
   "source": [
    "for s in range(4):\n",
    "    print(eval_model(spaces=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc937332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
